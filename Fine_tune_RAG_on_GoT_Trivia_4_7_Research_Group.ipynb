{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w58yjmjGPbdp",
        "yBs1iITx1lkY",
        "jAosJXvx8Sko"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f29faa366fb4823ac17ac72d36e0be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de3b25687de8453180e1600457d4f911",
              "IPY_MODEL_1591ae5f6eaa4dd9b3afeaa0d2940f10",
              "IPY_MODEL_8ae7284fe0d64ea4b18bc9063cffa679"
            ],
            "layout": "IPY_MODEL_cc189408de094d73836c88860ee289f5"
          }
        },
        "de3b25687de8453180e1600457d4f911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2235b505c6d4a4dacac3e71a596afbf",
            "placeholder": "​",
            "style": "IPY_MODEL_b1957bf9ca0e4b14b3a392f2e01bbdd6",
            "value": "100%"
          }
        },
        "1591ae5f6eaa4dd9b3afeaa0d2940f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b576967d407f46169b1b61098537c008",
            "max": 44,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f7dd5f206a24c9697b199425460cc2d",
            "value": 44
          }
        },
        "8ae7284fe0d64ea4b18bc9063cffa679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee1c70608564309917abb3ae78e4205",
            "placeholder": "​",
            "style": "IPY_MODEL_47f369edc4074c52b9b1ec11cc1c64da",
            "value": " 44/44 [01:31&lt;00:00,  1.93s/it]"
          }
        },
        "cc189408de094d73836c88860ee289f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2235b505c6d4a4dacac3e71a596afbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1957bf9ca0e4b14b3a392f2e01bbdd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b576967d407f46169b1b61098537c008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7dd5f206a24c9697b199425460cc2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ee1c70608564309917abb3ae78e4205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f369edc4074c52b9b1ec11cc1c64da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed051d0b9f8e46c4a44d2d20d6b15089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30eddacf930b4e13a708246858896826",
              "IPY_MODEL_8b25f9649c5f41f58c8c13032df9623f",
              "IPY_MODEL_018245b234014e3aaf2d6ca0e11a7a7a"
            ],
            "layout": "IPY_MODEL_ad376d7f2c4d4b4a9d2b9e6439eb2558"
          }
        },
        "30eddacf930b4e13a708246858896826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2f2efd62beb4a67a249f34637e465a5",
            "placeholder": "​",
            "style": "IPY_MODEL_607c0d3fc64d4966b864d571d4f3606f",
            "value": "Downloading: 100%"
          }
        },
        "8b25f9649c5f41f58c8c13032df9623f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_582a60c5b3f34c229191c66d39c1cd31",
            "max": 4550,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59ad5b03e84647089bc58e726db4a430",
            "value": 4550
          }
        },
        "018245b234014e3aaf2d6ca0e11a7a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9735d3260077490b9c1f7836dffab75b",
            "placeholder": "​",
            "style": "IPY_MODEL_98cf08ca95d8451aae41449e7558571a",
            "value": " 4.44k/4.44k [00:00&lt;00:00, 131kB/s]"
          }
        },
        "ad376d7f2c4d4b4a9d2b9e6439eb2558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f2efd62beb4a67a249f34637e465a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607c0d3fc64d4966b864d571d4f3606f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "582a60c5b3f34c229191c66d39c1cd31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59ad5b03e84647089bc58e726db4a430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9735d3260077490b9c1f7836dffab75b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98cf08ca95d8451aae41449e7558571a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c842742905a4aa7ae1d0e8877bf2711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d53084a265b04bb0b00ef46f3c89d457",
              "IPY_MODEL_277e4bb5bf2243b195b04b243e2f327f",
              "IPY_MODEL_90060639b5d24b4593b3cceed1887d56"
            ],
            "layout": "IPY_MODEL_a43582b72ad047b881f07223905d56c5"
          }
        },
        "d53084a265b04bb0b00ef46f3c89d457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2653e7dc15fc459bb2182fac64568d5b",
            "placeholder": "​",
            "style": "IPY_MODEL_bc411a19dbea42b8862944fb712693ab",
            "value": "Downloading: 100%"
          }
        },
        "277e4bb5bf2243b195b04b243e2f327f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed2fd6649f9a47cb93b5b20232b8eca0",
            "max": 4602,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92e6a5bc7d6344a6b20cd8bb0a0ad6ec",
            "value": 4602
          }
        },
        "90060639b5d24b4593b3cceed1887d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48665fa463604d7783f8d75b245fe166",
            "placeholder": "​",
            "style": "IPY_MODEL_2242d2562feb477783fb9ca3d93cfe87",
            "value": " 4.49k/4.49k [00:00&lt;00:00, 73.7kB/s]"
          }
        },
        "a43582b72ad047b881f07223905d56c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2653e7dc15fc459bb2182fac64568d5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc411a19dbea42b8862944fb712693ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed2fd6649f9a47cb93b5b20232b8eca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e6a5bc7d6344a6b20cd8bb0a0ad6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48665fa463604d7783f8d75b245fe166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2242d2562feb477783fb9ca3d93cfe87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35b76c8a357a4565930b7971604ebd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8668f4719e414cda971c7ff45071cbc1",
              "IPY_MODEL_57449044342e4e7c97629f15e68a7404",
              "IPY_MODEL_7b42b0bb68f4445b962de6c32bf92bd5"
            ],
            "layout": "IPY_MODEL_becee9b002e3495ba0edb62478350d72"
          }
        },
        "8668f4719e414cda971c7ff45071cbc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8657f7eeb594ce48b5271f17b2e9540",
            "placeholder": "​",
            "style": "IPY_MODEL_c91eeddfcb274f7297a8bbf14292de4f",
            "value": "Downloading: 100%"
          }
        },
        "57449044342e4e7c97629f15e68a7404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4622a76aa224d9585c7a8f4b0c5f4eb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c5c6c85d7bb4378b5ec05a9e502a8b0",
            "value": 231508
          }
        },
        "7b42b0bb68f4445b962de6c32bf92bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a792477e361c45b18e9213fd14456ede",
            "placeholder": "​",
            "style": "IPY_MODEL_12233f931651460ebfee0aca16df27b1",
            "value": " 226k/226k [00:00&lt;00:00, 225kB/s]"
          }
        },
        "becee9b002e3495ba0edb62478350d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8657f7eeb594ce48b5271f17b2e9540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c91eeddfcb274f7297a8bbf14292de4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4622a76aa224d9585c7a8f4b0c5f4eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5c6c85d7bb4378b5ec05a9e502a8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a792477e361c45b18e9213fd14456ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12233f931651460ebfee0aca16df27b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4828cfaca0f640cc859778376b31ddad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_602210ab08e04314a4dc279185363689",
              "IPY_MODEL_878e62de3d824da39c6f795a7d9d48c2",
              "IPY_MODEL_44fac7f298564ad79c835a3d89892966"
            ],
            "layout": "IPY_MODEL_5c739719c8ee4752b7c106662fc3029d"
          }
        },
        "602210ab08e04314a4dc279185363689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b081c6c94a5490bb4b0db26cf2b1971",
            "placeholder": "​",
            "style": "IPY_MODEL_8fada775a60244a09612c33b16f950af",
            "value": "Downloading: 100%"
          }
        },
        "878e62de3d824da39c6f795a7d9d48c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86454a255e8e4927b45744318325504a",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_404c8f3e9955455bb14cc2361dbde876",
            "value": 112
          }
        },
        "44fac7f298564ad79c835a3d89892966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01671fecd42e4a8bb866fb461e4ee84e",
            "placeholder": "​",
            "style": "IPY_MODEL_7228d7a24a364768bf461d9bccc41f99",
            "value": " 112/112 [00:00&lt;00:00, 3.24kB/s]"
          }
        },
        "5c739719c8ee4752b7c106662fc3029d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b081c6c94a5490bb4b0db26cf2b1971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fada775a60244a09612c33b16f950af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86454a255e8e4927b45744318325504a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "404c8f3e9955455bb14cc2361dbde876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01671fecd42e4a8bb866fb461e4ee84e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7228d7a24a364768bf461d9bccc41f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b12357d4d86430c8d94b83c89f62e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30dcc9adda4e496c9334f916d127a4b0",
              "IPY_MODEL_98575368190242a6ab1d41976684f9f5",
              "IPY_MODEL_ac87185fe0b549a8a0bb2ab829b96cd5"
            ],
            "layout": "IPY_MODEL_ca6fc6c975f748f88a5617fed702a563"
          }
        },
        "30dcc9adda4e496c9334f916d127a4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62dc23cb8df64b35927252a3be32461f",
            "placeholder": "​",
            "style": "IPY_MODEL_616c9e6c7719448db3e64b5fe2474e94",
            "value": "Downloading: 100%"
          }
        },
        "98575368190242a6ab1d41976684f9f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c57826a5f94c4504a6e7c8c3c60ffe7f",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a3739825dee4466875ca2b509b35ef4",
            "value": 48
          }
        },
        "ac87185fe0b549a8a0bb2ab829b96cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ca59c3ed67740cc9a9854b3a4ecb628",
            "placeholder": "​",
            "style": "IPY_MODEL_e46eb86f9e7c4429a69152b52a06561b",
            "value": " 48.0/48.0 [00:00&lt;00:00, 595B/s]"
          }
        },
        "ca6fc6c975f748f88a5617fed702a563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62dc23cb8df64b35927252a3be32461f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "616c9e6c7719448db3e64b5fe2474e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c57826a5f94c4504a6e7c8c3c60ffe7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a3739825dee4466875ca2b509b35ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ca59c3ed67740cc9a9854b3a4ecb628": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46eb86f9e7c4429a69152b52a06561b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb2e593bd4714e249f67f5d5413298b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb9bcb967bde47e8893faa1a7261d940",
              "IPY_MODEL_c00fa079e77741b797a483c0ad61d04e",
              "IPY_MODEL_ef66d13030ee4ceb8181752fd2401378"
            ],
            "layout": "IPY_MODEL_dfbec298822d476185ada22c9e2bd0a5"
          }
        },
        "eb9bcb967bde47e8893faa1a7261d940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1109097548434c9d2933c022dbed99",
            "placeholder": "​",
            "style": "IPY_MODEL_51f8167da39d492d912f3252f3525994",
            "value": "Downloading: 100%"
          }
        },
        "c00fa079e77741b797a483c0ad61d04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d88d54079d194bf1b3eb421405748dbe",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25e16435aaf14757b01fbf46889ac8b9",
            "value": 898822
          }
        },
        "ef66d13030ee4ceb8181752fd2401378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2e66a8dc47b4a6d9309f10588b0da62",
            "placeholder": "​",
            "style": "IPY_MODEL_35ff2127697b49e19a9a5b00e85d8c2a",
            "value": " 878k/878k [00:01&lt;00:00, 985kB/s]"
          }
        },
        "dfbec298822d476185ada22c9e2bd0a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b1109097548434c9d2933c022dbed99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f8167da39d492d912f3252f3525994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d88d54079d194bf1b3eb421405748dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e16435aaf14757b01fbf46889ac8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2e66a8dc47b4a6d9309f10588b0da62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ff2127697b49e19a9a5b00e85d8c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8e10137a1f4d18a09f7348712b7590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62ca5df71fc84444800e5a26ec9b8dc7",
              "IPY_MODEL_14dc62b8297b4772ab2ea3337415fb06",
              "IPY_MODEL_62db750c25a14eed8f61a13cd5c924a7"
            ],
            "layout": "IPY_MODEL_d9573248081d426087b1d36b8bdb9840"
          }
        },
        "62ca5df71fc84444800e5a26ec9b8dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e73b565b91f24337bb1ec5c4b91b1f03",
            "placeholder": "​",
            "style": "IPY_MODEL_0a55663c03164640a19ac761c3795141",
            "value": "Downloading: 100%"
          }
        },
        "14dc62b8297b4772ab2ea3337415fb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21307a6052d47599d1876d193c9210a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0db2585f2437423d9f5928135f19378c",
            "value": 456318
          }
        },
        "62db750c25a14eed8f61a13cd5c924a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aeb94c22bdf4879823ef861335c4f83",
            "placeholder": "​",
            "style": "IPY_MODEL_b6ecf0e7038a4398a8680412950f4adf",
            "value": " 446k/446k [00:01&lt;00:00, 522kB/s]"
          }
        },
        "d9573248081d426087b1d36b8bdb9840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73b565b91f24337bb1ec5c4b91b1f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a55663c03164640a19ac761c3795141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f21307a6052d47599d1876d193c9210a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db2585f2437423d9f5928135f19378c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7aeb94c22bdf4879823ef861335c4f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6ecf0e7038a4398a8680412950f4adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee62f0c5091a4610b0c2130ceccd617f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a71fd5c770a4d99ac20b276396a0822",
              "IPY_MODEL_21415d160462469c8b17b0f295f5051b",
              "IPY_MODEL_fdef8f92395541c7b71979e19647256e"
            ],
            "layout": "IPY_MODEL_7799913e4feb4b3b8b440cb052350e91"
          }
        },
        "8a71fd5c770a4d99ac20b276396a0822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d27e125bd13d40fa8f6cf43907438596",
            "placeholder": "​",
            "style": "IPY_MODEL_cadf28a0fb1041739a9301ec25cb610c",
            "value": "Downloading: 100%"
          }
        },
        "21415d160462469c8b17b0f295f5051b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_193e00edb52e43eea4ad5d1240eb31f6",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2acbf9b91a1e4fd794eb07f494847ccf",
            "value": 772
          }
        },
        "fdef8f92395541c7b71979e19647256e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ee835693c54a95b0629188467bd376",
            "placeholder": "​",
            "style": "IPY_MODEL_d4d10fed4abe4d1aa129ec4ee1a68394",
            "value": " 772/772 [00:00&lt;00:00, 23.4kB/s]"
          }
        },
        "7799913e4feb4b3b8b440cb052350e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d27e125bd13d40fa8f6cf43907438596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cadf28a0fb1041739a9301ec25cb610c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "193e00edb52e43eea4ad5d1240eb31f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2acbf9b91a1e4fd794eb07f494847ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23ee835693c54a95b0629188467bd376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d10fed4abe4d1aa129ec4ee1a68394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "884cfdf03c6f43029c2114fd05b751c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_504c0000b0274ca1bb03b60e699bf98b",
              "IPY_MODEL_1953a69d81ba4e4e914299f7e3f41f57",
              "IPY_MODEL_53959cf461214502b5dae27580715d1e"
            ],
            "layout": "IPY_MODEL_e8654e1a8625478eab6f2f65a6b10836"
          }
        },
        "504c0000b0274ca1bb03b60e699bf98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_145b13cc26e84d58bc453d323da263d9",
            "placeholder": "​",
            "style": "IPY_MODEL_56e07ae29d3f4c8fb4c520ccbf0cd4f9",
            "value": "Downloading: 100%"
          }
        },
        "1953a69d81ba4e4e914299f7e3f41f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6229c919620a49e3af60dc79c522260d",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38b726cae5994a519c45fb631087f431",
            "value": 26
          }
        },
        "53959cf461214502b5dae27580715d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_941e67c0d85141028540d194f4c412e4",
            "placeholder": "​",
            "style": "IPY_MODEL_28cc6d87a8274f1b8a1fd4fec9d451ad",
            "value": " 26.0/26.0 [00:00&lt;00:00, 806B/s]"
          }
        },
        "e8654e1a8625478eab6f2f65a6b10836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "145b13cc26e84d58bc453d323da263d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56e07ae29d3f4c8fb4c520ccbf0cd4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6229c919620a49e3af60dc79c522260d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b726cae5994a519c45fb631087f431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "941e67c0d85141028540d194f4c412e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28cc6d87a8274f1b8a1fd4fec9d451ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b98f720ee2f5455a833cf0a07daa1ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7412bb5a7e8f4d4989a063a1a6158198",
              "IPY_MODEL_70083b97b9704666a6aee2ab42020cc5",
              "IPY_MODEL_ca9f228ad0634b1db883e4c06293004a"
            ],
            "layout": "IPY_MODEL_add8d28d6b564ed9b1165023a55758bd"
          }
        },
        "7412bb5a7e8f4d4989a063a1a6158198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d3a2065e614398999ea47af1db9edd",
            "placeholder": "​",
            "style": "IPY_MODEL_5976b035c5884a6ca3c84a9ba82b051f",
            "value": "Downloading: 100%"
          }
        },
        "70083b97b9704666a6aee2ab42020cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b65d8908de2483fb32cd20c65c11b1e",
            "max": 2063600064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d31ff000ef944efb9abd24f8f5fe081",
            "value": 2063600064
          }
        },
        "ca9f228ad0634b1db883e4c06293004a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d05ac948644648fb9a9e7b0573ccff46",
            "placeholder": "​",
            "style": "IPY_MODEL_85d6f5a5ff804f1d9dac8673a2b3f783",
            "value": " 1.92G/1.92G [00:39&lt;00:00, 58.4MB/s]"
          }
        },
        "add8d28d6b564ed9b1165023a55758bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d3a2065e614398999ea47af1db9edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5976b035c5884a6ca3c84a9ba82b051f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b65d8908de2483fb32cd20c65c11b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d31ff000ef944efb9abd24f8f5fe081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d05ac948644648fb9a9e7b0573ccff46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85d6f5a5ff804f1d9dac8673a2b3f783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d3bde393442470ba508a7f387cd0e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0203690799334f63a115338b03fc79ea",
              "IPY_MODEL_13f958e13e95406bba1ddd97d1d75973",
              "IPY_MODEL_51b2bca1dedc4cfdabd5f8199cff2131"
            ],
            "layout": "IPY_MODEL_aa09accaee5e414d95c35166dfc030b0"
          }
        },
        "0203690799334f63a115338b03fc79ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe1f384b7ec8464e84094b7f2d245e59",
            "placeholder": "​",
            "style": "IPY_MODEL_9e358e3b464f4fb2bfab6148869306ab",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "13f958e13e95406bba1ddd97d1d75973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec90295e1c98412788c4d23e2fdba8ac",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b40a7b037554e32b5b21fadcada56b3",
            "value": 1
          }
        },
        "51b2bca1dedc4cfdabd5f8199cff2131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d6b19156c80438bb3d9587c2a3394da",
            "placeholder": "​",
            "style": "IPY_MODEL_b2a8da355b314c8593719a09ed01f966",
            "value": " 1/1 [00:04&lt;00:00,  4.22s/it]"
          }
        },
        "aa09accaee5e414d95c35166dfc030b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "fe1f384b7ec8464e84094b7f2d245e59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e358e3b464f4fb2bfab6148869306ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec90295e1c98412788c4d23e2fdba8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b40a7b037554e32b5b21fadcada56b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d6b19156c80438bb3d9587c2a3394da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a8da355b314c8593719a09ed01f966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca50d9af846d451a8b89b31eee7c2e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b3ca0ddb5564585957390303d41d249",
              "IPY_MODEL_d0ef7e3f7d024a8e9d862e6f2a6a2f1d",
              "IPY_MODEL_9e697086be6b4d83ba7feacd3df19840"
            ],
            "layout": "IPY_MODEL_274e0e4435b341288931aeb459213013"
          }
        },
        "9b3ca0ddb5564585957390303d41d249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29726764860843f4b2a0b709ff32f02f",
            "placeholder": "​",
            "style": "IPY_MODEL_8a43b378c190452fb68257bc486243f7",
            "value": "Epoch 2: 100%"
          }
        },
        "d0ef7e3f7d024a8e9d862e6f2a6a2f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_022c6a5d2e3f48409eb97de024e7deb0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4334055a3bad4d988bd696f6d17f3b0d",
            "value": 1
          }
        },
        "9e697086be6b4d83ba7feacd3df19840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2748da67ad84404a3e0d640385d5f93",
            "placeholder": "​",
            "style": "IPY_MODEL_fc13d66d83284e408e564ee5793d1647",
            "value": " 115/115 [02:57&lt;00:00,  1.55s/it, loss=2.27, v_num=1]"
          }
        },
        "274e0e4435b341288931aeb459213013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "29726764860843f4b2a0b709ff32f02f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a43b378c190452fb68257bc486243f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "022c6a5d2e3f48409eb97de024e7deb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4334055a3bad4d988bd696f6d17f3b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2748da67ad84404a3e0d640385d5f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc13d66d83284e408e564ee5793d1647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66a709d1f8ed4215a6b5a836056befce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d06b3782e74f91985857af13230473",
              "IPY_MODEL_05fa5929b11048818e5e04e83ec6a3e7",
              "IPY_MODEL_bcc0ddf449a44b1ab1cbe75bd0792dd9"
            ],
            "layout": "IPY_MODEL_13d57c0d2ca14b63b241bf3fe0ebc6ac"
          }
        },
        "11d06b3782e74f91985857af13230473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3a1e4f5bb1e4f26980db6b9a14b4c7b",
            "placeholder": "​",
            "style": "IPY_MODEL_90d74685e00d4516a63975743f2001ba",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "05fa5929b11048818e5e04e83ec6a3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b99a4c2dfc424324ba70a486ac607a98",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ef0a923b91747ac9fc34147d290e313",
            "value": 1
          }
        },
        "bcc0ddf449a44b1ab1cbe75bd0792dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7821a17c18f04ebface06d1e7ace1e9a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb3d0b28960c41a28dbbc9502ef86b78",
            "value": " 1/1 [00:04&lt;00:00,  4.04s/it]"
          }
        },
        "13d57c0d2ca14b63b241bf3fe0ebc6ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "f3a1e4f5bb1e4f26980db6b9a14b4c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d74685e00d4516a63975743f2001ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b99a4c2dfc424324ba70a486ac607a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef0a923b91747ac9fc34147d290e313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7821a17c18f04ebface06d1e7ace1e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3d0b28960c41a28dbbc9502ef86b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45496669456146788089b4a2232f830d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a9650142ecd4baeb0f0c36a2adf1e2c",
              "IPY_MODEL_72a3ac70e90542e49246d10303d801cf",
              "IPY_MODEL_e0d979d9e8974983a76f81778b9d0be4"
            ],
            "layout": "IPY_MODEL_d76ad57794164052a9f0d5658290abfa"
          }
        },
        "1a9650142ecd4baeb0f0c36a2adf1e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbbe813976a14103b6b8289868a255e1",
            "placeholder": "​",
            "style": "IPY_MODEL_85cd550207ce4eeeaba5e760080be63e",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "72a3ac70e90542e49246d10303d801cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50dbec4f75a496da6b985c406eebe46",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a4a2eeca5b04096a3c9e9d647cb0523",
            "value": 1
          }
        },
        "e0d979d9e8974983a76f81778b9d0be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee484876697453d8fa81d8721feeacd",
            "placeholder": "​",
            "style": "IPY_MODEL_6e476c7fa64d4b31a7feac5901aac068",
            "value": " 1/1 [00:04&lt;00:00,  4.09s/it]"
          }
        },
        "d76ad57794164052a9f0d5658290abfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "dbbe813976a14103b6b8289868a255e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85cd550207ce4eeeaba5e760080be63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b50dbec4f75a496da6b985c406eebe46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4a2eeca5b04096a3c9e9d647cb0523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dee484876697453d8fa81d8721feeacd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e476c7fa64d4b31a7feac5901aac068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01b6498a155c4bfaa30d46c2ada6053f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28495c5c3eb04403945e49400f108026",
              "IPY_MODEL_5eefb6ca19f64014b46f96de4580617b",
              "IPY_MODEL_9bec16aa526242a9b040f5eb404bd44e"
            ],
            "layout": "IPY_MODEL_9a957967d428458d9c4b291f47754ade"
          }
        },
        "28495c5c3eb04403945e49400f108026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4feb01b423724a0c9eb7e08296068f45",
            "placeholder": "​",
            "style": "IPY_MODEL_70f5b41292234c339821b05f9844dc15",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "5eefb6ca19f64014b46f96de4580617b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40306e9d78634882a929d4363c0cd357",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8eaf2b37fbf242178e430454f9b7fd9d",
            "value": 1
          }
        },
        "9bec16aa526242a9b040f5eb404bd44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6adad24c069f4e73887323e5eaddb7e6",
            "placeholder": "​",
            "style": "IPY_MODEL_4c50fbfd64f24b2a9c28f15377499b8f",
            "value": " 1/1 [00:04&lt;00:00,  4.18s/it]"
          }
        },
        "9a957967d428458d9c4b291f47754ade": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "4feb01b423724a0c9eb7e08296068f45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f5b41292234c339821b05f9844dc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40306e9d78634882a929d4363c0cd357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eaf2b37fbf242178e430454f9b7fd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6adad24c069f4e73887323e5eaddb7e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c50fbfd64f24b2a9c28f15377499b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "976b2eac1d4b43aa97384aa926bb5aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a553bc1b204b4e07a70c6e241d4a9a73",
              "IPY_MODEL_891e963f1c9941e097cbf93ed3010ab4",
              "IPY_MODEL_3c81fb48d3914d22aa3613c0f4f4462e"
            ],
            "layout": "IPY_MODEL_4ba75d35d10f477fb7cb956b0717119a"
          }
        },
        "a553bc1b204b4e07a70c6e241d4a9a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e20746414b24e1a82e3f2a2fa62f5ad",
            "placeholder": "​",
            "style": "IPY_MODEL_aa7e663d6582481fb3f820e4b9fb9f7d",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "891e963f1c9941e097cbf93ed3010ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a57594f7c09e474291a0a9b2773bc38a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92092c50d9274473814347c4b42f28b5",
            "value": 1
          }
        },
        "3c81fb48d3914d22aa3613c0f4f4462e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa5b7d130184bc8915e02a882d196be",
            "placeholder": "​",
            "style": "IPY_MODEL_5143fc1190a244188157b667533d8fed",
            "value": " 1/1 [00:04&lt;00:00,  4.90s/it]"
          }
        },
        "4ba75d35d10f477fb7cb956b0717119a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5e20746414b24e1a82e3f2a2fa62f5ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa7e663d6582481fb3f820e4b9fb9f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a57594f7c09e474291a0a9b2773bc38a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92092c50d9274473814347c4b42f28b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfa5b7d130184bc8915e02a882d196be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5143fc1190a244188157b667533d8fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "OH5pQiA1qOex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a copy of the Notebook in the state it was in for our research group on Thursday, April 7th. It's definitely unfinished, but you're welcome to look through it, and the notes from the group are included below. \n",
        "\n"
      ],
      "metadata": {
        "id": "9o0m8gRCI4Ml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I.1. Weekly Research Group, 4/7/22"
      ],
      "metadata": {
        "id": "DW9nc2HmHbNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HuggingFace `finetune_rag.py` Script**\n",
        "\n",
        "* Script is [here](https://github.com/huggingface/transformers/blob/main/examples/research_projects/rag/finetune_rag.py).\n",
        "\n",
        "* Command-line tool, main purpose is distributed training \n",
        "    * (distributed retrieval in particular).\n",
        "\n",
        "* Built on PyTorch Lightning.\n",
        "    * You define a \"Module\" class that must implement some key methods for training.\n",
        "\n",
        "* The script mainly implements the usual training and test steps--the model implementation is really down in `RagTokenForGeneration` and `BartForConditionalGeneration`\n",
        "\n",
        "* Fine-tuning example is under `research`.\n"
      ],
      "metadata": {
        "id": "N154BsGjqgug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Process**\n",
        "\n",
        "* Had trouble getting the tool to use our GoT dataset.\n",
        "* To inspect and organize the code, I:\n",
        "    * Dump the script contents into a Notebook\n",
        "    * Fake the command line arguments\n",
        "    * Flatten the code\n"
      ],
      "metadata": {
        "id": "G1CHc7yjrUT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Trivia Performance**\n",
        "\n",
        "* Doesn't appear to be tripped up by fill-in-the-blank or \"implied\" questions.\n",
        "* Don't understand yet how the decoding style changes after fine-tuning.\n",
        "    * **TODO** - Try stripping the capitalization from my training \"targets\"--see if the model produces lower case answers instead.\n",
        "* Fine-tuning is currently making it worse--there may be bugs.\n",
        "    * After fine-tuning, there are questions where it is getting the \"fill-in-the-blank\" version correct, but the proper question format wrong\n",
        "        * So... Maybe it's unlearning the question format in favor of fill-in-the-blank\n",
        "            * **TODO** - Try removing / fixing the fill-in-the-blank questions and see if it does better!\n",
        "\n",
        "_More Observations_\n",
        "\n",
        "* If we reformatted our answers as complete sentences, would RAG learn to do the same?\n",
        "* We tried a couple easy yes or no questions that it failed on...\n",
        "* We tried a couple \"why\" (give an explanation) type questions, and it got them wrong, but did answer in the right format (e.g., \"because of a technical error\").\n",
        "* Transformers have some resilience to misspellings because of subwords. Mareen vs. Meereen -- Both share the \"reen\" subword, which can encode some information about the city.\n",
        "\n"
      ],
      "metadata": {
        "id": "iUvLS3I-qP4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Trivia Question Sources**\n",
        "\n",
        "* Most aren't easily downloadable.\n",
        "* Crafting my own from articles is slower than expected! (1 minute each??)\n",
        "    * Copy-pasting individually from websites is probably faster.\n",
        "* Interesting that many questions would involve reasoning:\n",
        "    * “Give the reason for xyz”\n",
        "    * “Why was Robb motivated to revolt against xyz” \n",
        "    * “Why does Hodor say “Hodor”?”\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HE7R32OsqfG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summarization / Paraphrasing**\n",
        "\n",
        "* [Chris] - I believe RAG authors report improvements on summarization benchmarks?\n",
        "* [Chris] - Maybe retrieval can help in that the retriever could decide which passages from a large document are most helpful to the summarization.\n",
        "    * RAG is able to incorporate multiple shorter length passages (to get around Transformer input length limitations) into its generated result."
      ],
      "metadata": {
        "id": "asmZIp2V9MjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next Steps**\n",
        "\n",
        "* Use a consistent question form (remove any fill-in-the-blanks or implied questions) and see if it performs better.\n",
        "    * Maybe remove periods, since those are inconsistent as well.\n",
        "* Try formatting the questions as complete sentences to see how well it adapts to generating in that format.\n",
        "* Work on scoring...\n",
        "    * Currently does exact match.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "__TddWS5uOWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S1. Setup & Datasets"
      ],
      "metadata": {
        "id": "folOJI_ckCxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Install Packages"
      ],
      "metadata": {
        "id": "w58yjmjGPbdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HskLUkNvQ-z4",
        "outputId": "d5b89f12-5ebd-4393-d150-df663e8da14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve the `requirements.txt` file which specifies the packages (and their specific version numbers) to install."
      ],
      "metadata": {
        "id": "ShrY0ppcSlkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "\n",
        "wget.download(\"https://raw.githubusercontent.com/huggingface/transformers/main/examples/research_projects/rag/requirements.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YJYRU1urRAlo",
        "outputId": "8c214737-4796-4af8-e3bc-6b0efd5edd26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'requirements.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install `transformers` and other packages required for this example."
      ],
      "metadata": {
        "id": "PWo1D7RKShiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "jdUCbd7OQ8X6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f60c22a-38ce-4fa3-b7b5-7ade776c8ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu>=1.6.3\n",
            "  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 15.1 MB/s \n",
            "\u001b[?25hCollecting datasets>=1.0.1\n",
            "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 56.1 MB/s \n",
            "\u001b[?25hCollecting psutil>=5.7.0\n",
            "  Downloading psutil-5.9.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.10.0+cu111)\n",
            "Collecting ray>=1.10.0\n",
            "  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 52.7 MB 134 kB/s \n",
            "\u001b[?25hCollecting pytorch-lightning>=1.5.10\n",
            "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
            "\u001b[K     |████████████████████████████████| 582 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 61.7 MB/s \n",
            "\u001b[?25hCollecting GitPython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 17.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (1.21.5)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (4.11.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (0.3.4)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.0.1->-r requirements.txt (line 2)) (0.70.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 4)) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray>=1.10.0->-r requirements.txt (line 5)) (3.6.0)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray>=1.10.0->-r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray>=1.10.0->-r requirements.txt (line 5)) (21.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.10.0->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray>=1.10.0->-r requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.10.0->-r requirements.txt (line 5)) (1.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray>=1.10.0->-r requirements.txt (line 5)) (3.13)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 65.5 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Collecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.8 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.7.3-py3-none-any.whl (398 kB)\n",
            "\u001b[K     |████████████████████████████████| 398 kB 15.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (2.8.0)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray>=1.10.0->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.0.1->-r requirements.txt (line 2)) (3.0.7)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting async-timeout>=4.0.2\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray>=1.10.0->-r requirements.txt (line 5)) (1.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets>=1.0.1->-r requirements.txt (line 2)) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.0.1->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.0.1->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.0.1->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.0.1->-r requirements.txt (line 2)) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 76.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.5.10->-r requirements.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 7)) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 57.0 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.6 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 73.7 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 14.2 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.0.1->-r requirements.txt (line 2)) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray>=1.10.0->-r requirements.txt (line 5)) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray>=1.10.0->-r requirements.txt (line 5)) (0.18.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.0.1->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.0.1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 7)) (1.1.0)\n",
            "Installing collected packages: urllib3, typing-extensions, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, smmap, pyyaml, pyDeprecate, grpcio, fsspec, deprecated, aiohttp, xxhash, torchmetrics, tokenizers, sacremoses, responses, redis, huggingface-hub, gitdb, transformers, ray, pytorch-lightning, psutil, GitPython, faiss-cpu, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.1.1 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 deprecated-1.2.13 faiss-cpu-1.7.2 frozenlist-1.3.0 fsspec-2022.3.0 gitdb-4.0.9 grpcio-1.43.0 huggingface-hub-0.5.1 multidict-6.0.2 psutil-5.9.0 pyDeprecate-0.3.2 pytorch-lightning-1.6.0 pyyaml-6.0 ray-1.11.0 redis-4.2.2 responses-0.18.0 sacremoses-0.0.49 smmap-5.0.0 tokenizers-0.11.6 torchmetrics-0.7.3 transformers-4.18.0 typing-extensions-4.1.1 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iODkmnOr4Nn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Load Reference Text Dataset"
      ],
      "metadata": {
        "id": "yBs1iITx1lkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Specify the name to give the file locally. \n",
        "output = 'got_hf_dataset.zip'\n",
        "    \n",
        "# Specify the Google Drive ID of the file.\n",
        "file_id = '1VCCeTBgcCXaJOEupGt--1L8AAVeDeY_a' # This is currently called 'articles.zip'\n",
        "\n",
        "# Download the file.\n",
        "gdown.download('https://drive.google.com/uc?id=' + file_id, output, \n",
        "                quiet=False)\n",
        "\n",
        "print('DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPZATEyL1nQ2",
        "outputId": "1dd1301c-4287-448a-e5b5-ce357c87ffe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1VCCeTBgcCXaJOEupGt--1L8AAVeDeY_a \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the reference text dataset.\n",
        "!cp './drive/Shared drives/ChrisMcCormick.AI/Content/2021-08-20 - RAG/release/got_hf_dataset.zip' ."
      ],
      "metadata": {
        "id": "QjmElNfgmXtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip the file."
      ],
      "metadata": {
        "id": "IH4iuvxJ2Wmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "data_dir = '.'\n",
        "\n",
        "# Check out the sizes on the saved files.\n",
        "files = list(os.listdir(data_dir))\n",
        "\n",
        "print(data_dir)\n",
        "\n",
        "# For each file in the directory...\n",
        "for f in files:\n",
        "    # Get the file size, in MB\n",
        "    f_size = float(os.stat(data_dir + '/' + f).st_size) / 2**20\n",
        "    \n",
        "    # Print the filename and its size.\n",
        "    print(\"     {:25s}    {:>6.2f} MB\".format(f, f_size))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuNK1uF-lens",
        "outputId": "678b1b80-0801-41ea-8e30-4a806141282e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "     .config                        0.00 MB\n",
            "     got_hf_dataset.zip           125.15 MB\n",
            "     drive                          0.00 MB\n",
            "     requirements.txt               0.00 MB\n",
            "     sample_data                    0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip got_hf_dataset.zip -d got_hf_dataset\n",
        "\n",
        "# -o will force it to overwrite what's there.\n",
        "!unzip -o got_hf_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ry80fP2MR3",
        "outputId": "f594dc01-4ee1-482f-c5f2-0fd05b9070b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  got_hf_dataset.zip\n",
            "   creating: got_dataset/\n",
            "  inflating: got_dataset/state.json  \n",
            "  inflating: got_dataset/dataset.arrow  \n",
            "  inflating: got_dataset/dataset_info.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load it in as a huggingface dataset object."
      ],
      "metadata": {
        "id": "rp3QDMgJ2i77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_from_disk\n",
        "\n",
        "got_dataset = load_from_disk(\"./got_dataset\")\n"
      ],
      "metadata": {
        "id": "guJBrTRQ2YmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "got_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoQ1fYeF2mfU",
        "outputId": "aae92941-372f-467a-fb20-9d8917e1dd1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['title', 'text', 'embeddings'],\n",
              "    num_rows: 43151\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the required index."
      ],
      "metadata": {
        "id": "H6hegVxn2nIP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF3UARo_dnxB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "9f29faa366fb4823ac17ac72d36e0be7",
            "de3b25687de8453180e1600457d4f911",
            "1591ae5f6eaa4dd9b3afeaa0d2940f10",
            "8ae7284fe0d64ea4b18bc9063cffa679",
            "cc189408de094d73836c88860ee289f5",
            "e2235b505c6d4a4dacac3e71a596afbf",
            "b1957bf9ca0e4b14b3a392f2e01bbdd6",
            "b576967d407f46169b1b61098537c008",
            "0f7dd5f206a24c9697b199425460cc2d",
            "2ee1c70608564309917abb3ae78e4205",
            "47f369edc4074c52b9b1ec11cc1c64da"
          ]
        },
        "outputId": "dba80232-ba05-4c2c-ba3f-34e13cb27ab3"
      },
      "source": [
        "import faiss\n",
        "\n",
        "# \"The dimension of the embeddings to pass to the HNSW Faiss index.\"\n",
        "dim = 768\n",
        "\n",
        "# \"The number of bi-directional links created for every new element during the \n",
        "# HNSW index construction.\"\n",
        "m = 128\n",
        "\n",
        "# Let's use the Faiss implementation of HNSW for fast approximate nearest neighbor search\n",
        "index = faiss.IndexHNSWFlat(dim, m, faiss.METRIC_INNER_PRODUCT)\n",
        "\n",
        "got_dataset.add_faiss_index(column=\"embeddings\", index_name=\"embeddings\", custom_index=index, faiss_verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/44 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f29faa366fb4823ac17ac72d36e0be7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['title', 'text', 'embeddings'],\n",
              "    num_rows: 43151\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Load Trivia Questions"
      ],
      "metadata": {
        "id": "j-Rwu4NY46XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the reference text dataset.\n",
        "!cp './drive/Shared drives/ChrisMcCormick.AI/Content/2021-08-20 - RAG/release/dataset_130.zip' ."
      ],
      "metadata": {
        "id": "VJF6lSoo49qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip dataset_130.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B70d8u915JRz",
        "outputId": "6704a533-c87c-42e3-e91c-0005ff011176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dataset_130.zip\n",
            "  inflating: dataset_130/test.source  \n",
            "  inflating: dataset_130/test.target  \n",
            "  inflating: dataset_130/train.source  \n",
            "  inflating: dataset_130/train.target  \n",
            "  inflating: dataset_130/val.source  \n",
            "  inflating: dataset_130/val.target  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./dataset_130/ ./data/"
      ],
      "metadata": {
        "id": "zXbD4BWx7I1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ./dataset/ ./data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n82PdiNw7KMU",
        "outputId": "00071616-46b6-4102-a809-12c23d8443ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat './dataset/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13lIMavj6R7n",
        "outputId": "fb612d30-5820-4027-a625-df447f7e7363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\t drive\t      got_hf_dataset.zip  sample_data\n",
            "dataset_130.zip  got_dataset  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S2. Function & Class Definitions"
      ],
      "metadata": {
        "id": "wpdKBDhhkeLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. \"utils_rag.py\""
      ],
      "metadata": {
        "id": "l6RUF5Bhs3Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import json\n",
        "import linecache\n",
        "import os\n",
        "import pickle\n",
        "import re\n",
        "import socket\n",
        "import string\n",
        "from collections import Counter\n",
        "from logging import getLogger\n",
        "from pathlib import Path\n",
        "from typing import Callable, Dict, Iterable, List\n",
        "\n",
        "import git\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from transformers import BartTokenizer, RagTokenizer, T5Tokenizer\n",
        "\n"
      ],
      "metadata": {
        "id": "riuu3uJos5yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def encode_line(tokenizer, line, max_length, padding_side, pad_to_max_length=True, return_tensors=\"pt\"):\n",
        "    \n",
        "    extra_kw = {\"add_prefix_space\": True} if isinstance(tokenizer, BartTokenizer) and not line.startswith(\" \") else {}\n",
        "    \n",
        "    tokenizer.padding_side = padding_side\n",
        "    \n",
        "    return tokenizer(\n",
        "        [line],\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\" if pad_to_max_length else None,\n",
        "        truncation=True,\n",
        "        return_tensors=return_tensors,\n",
        "        add_special_tokens=True,\n",
        "        **extra_kw,\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "et-pWfT0tB2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def trim_batch(\n",
        "    input_ids,\n",
        "    pad_token_id,\n",
        "    attention_mask=None,\n",
        "):\n",
        "    \"\"\"Remove columns that are populated exclusively by pad_token_id\"\"\"\n",
        "    keep_column_mask = input_ids.ne(pad_token_id).any(dim=0)\n",
        "    if attention_mask is None:\n",
        "        return input_ids[:, keep_column_mask]\n",
        "    else:\n",
        "        return (input_ids[:, keep_column_mask], attention_mask[:, keep_column_mask])\n",
        "\n"
      ],
      "metadata": {
        "id": "RPXMmKritIZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        data_dir,\n",
        "        max_source_length,\n",
        "        max_target_length,\n",
        "        type_path=\"train\",\n",
        "        n_obs=None,\n",
        "        src_lang=None,\n",
        "        tgt_lang=None,\n",
        "        prefix=\"\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.src_file = Path(data_dir).joinpath(type_path + \".source\")\n",
        "        self.tgt_file = Path(data_dir).joinpath(type_path + \".target\")\n",
        "        self.src_lens = self.get_char_lens(self.src_file)\n",
        "        self.max_source_length = max_source_length\n",
        "        self.max_target_length = max_target_length\n",
        "        assert min(self.src_lens) > 0, f\"found empty line in {self.src_file}\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.prefix = prefix\n",
        "        if n_obs is not None:\n",
        "            self.src_lens = self.src_lens[:n_obs]\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_lens)\n",
        "\n",
        "    def __getitem__(self, index) -> Dict[str, torch.Tensor]:\n",
        "        index = index + 1  # linecache starts at 1\n",
        "        \n",
        "        source_line = self.prefix + linecache.getline(str(self.src_file), index).rstrip(\"\\n\")\n",
        "        \n",
        "        tgt_line = linecache.getline(str(self.tgt_file), index).rstrip(\"\\n\")\n",
        "        \n",
        "        assert source_line, f\"empty source line for index {index}\"\n",
        "        assert tgt_line, f\"empty tgt line for index {index}\"\n",
        "\n",
        "        # Need to add eos token manually for T5\n",
        "        if isinstance(self.tokenizer, T5Tokenizer):\n",
        "            source_line += self.tokenizer.eos_token\n",
        "            tgt_line += self.tokenizer.eos_token\n",
        "\n",
        "        # Get the tokenizers...\n",
        "        # Pad source and target to the right\n",
        "        source_tokenizer = (\n",
        "            self.tokenizer.question_encoder if isinstance(self.tokenizer, RagTokenizer) else self.tokenizer\n",
        "        )\n",
        "        target_tokenizer = self.tokenizer.generator if isinstance(self.tokenizer, RagTokenizer) else self.tokenizer\n",
        "\n",
        "        # Encode input and desired output.\n",
        "        source_inputs = encode_line(source_tokenizer, source_line, self.max_source_length, \"right\")\n",
        "        \n",
        "        target_inputs = encode_line(target_tokenizer, tgt_line, self.max_target_length, \"right\")\n",
        "\n",
        "        source_ids = source_inputs[\"input_ids\"].squeeze()\n",
        "\n",
        "        target_ids = target_inputs[\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask = source_inputs[\"attention_mask\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": source_ids,\n",
        "            \"attention_mask\": src_mask,\n",
        "            \"decoder_input_ids\": target_ids,\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def get_char_lens(data_file):\n",
        "        return [len(x) for x in Path(data_file).open().readlines()]\n",
        "\n",
        "    def collate_fn(self, batch) -> Dict[str, torch.Tensor]:\n",
        "        input_ids = torch.stack([x[\"input_ids\"] for x in batch])\n",
        "        masks = torch.stack([x[\"attention_mask\"] for x in batch])\n",
        "        target_ids = torch.stack([x[\"decoder_input_ids\"] for x in batch])\n",
        "        tgt_pad_token_id = (\n",
        "            self.tokenizer.generator.pad_token_id\n",
        "            if isinstance(self.tokenizer, RagTokenizer)\n",
        "            else self.tokenizer.pad_token_id\n",
        "        )\n",
        "        src_pad_token_id = (\n",
        "            self.tokenizer.question_encoder.pad_token_id\n",
        "            if isinstance(self.tokenizer, RagTokenizer)\n",
        "            else self.tokenizer.pad_token_id\n",
        "        )\n",
        "        y = trim_batch(target_ids, tgt_pad_token_id)\n",
        "        source_ids, source_mask = trim_batch(input_ids, src_pad_token_id, attention_mask=masks)\n",
        "        batch = {\n",
        "            \"input_ids\": source_ids,\n",
        "            \"attention_mask\": source_mask,\n",
        "            \"decoder_input_ids\": y,\n",
        "        }\n",
        "        return batch\n",
        "\n"
      ],
      "metadata": {
        "id": "9gh_ivQ7tGlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logger = getLogger(__name__)\n",
        "\n",
        "\n",
        "def flatten_list(summary_ids: List[List]):\n",
        "    return [x for x in itertools.chain.from_iterable(summary_ids)]\n",
        "\n",
        "\n",
        "def save_git_info(folder_path: str) -> None:\n",
        "    \"\"\"Save git information to output_dir/git_log.json\"\"\"\n",
        "    repo_infos = get_git_info()\n",
        "    save_json(repo_infos, os.path.join(folder_path, \"git_log.json\"))\n",
        "\n",
        "\n",
        "def save_json(content, path, indent=4, **json_dump_kwargs):\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(content, f, indent=indent, **json_dump_kwargs)\n",
        "\n",
        "\n",
        "def load_json(path):\n",
        "    with open(path) as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def get_git_info():\n",
        "    repo = git.Repo(search_parent_directories=True)\n",
        "    repo_infos = {\n",
        "        \"repo_id\": str(repo),\n",
        "        \"repo_sha\": str(repo.head.object.hexsha),\n",
        "        \"repo_branch\": str(repo.active_branch),\n",
        "        \"hostname\": str(socket.gethostname()),\n",
        "    }\n",
        "    return repo_infos\n",
        "\n",
        "\n",
        "def lmap(f: Callable, x: Iterable) -> List:\n",
        "    \"\"\"list(map(f, x))\"\"\"\n",
        "    return list(map(f, x))\n",
        "\n",
        "\n",
        "def pickle_save(obj, path):\n",
        "    \"\"\"pickle.dump(obj, path)\"\"\"\n",
        "    with open(path, \"wb\") as f:\n",
        "        return pickle.dump(obj, f)\n",
        "\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "def calculate_exact_match(output_lns: List[str], reference_lns: List[str]) -> Dict:\n",
        "    \n",
        "    assert len(output_lns) == len(reference_lns)\n",
        "    \n",
        "    em = 0\n",
        "    \n",
        "    # For each token, count the number which match exactly.\n",
        "    for hypo, pred in zip(output_lns, reference_lns):\n",
        "        # Do a little cleaning of each string, but then check for exact \n",
        "        # string match.\n",
        "        em += (normalize_answer(hypo) == normalize_answer(pred))\n",
        "    \n",
        "    # Average the total exact matches over the sequence length.\n",
        "    if len(output_lns) > 0:\n",
        "        em /= len(output_lns)\n",
        "\n",
        "    return {\"em\": em}\n",
        "\n",
        "def set_extra_model_params(extra_params, hparams, config):\n",
        "    equivalent_param = {p: p for p in extra_params}\n",
        "    # T5 models don't have `dropout` param, they have `dropout_rate` instead\n",
        "    equivalent_param[\"dropout\"] = \"dropout_rate\"\n",
        "    for p in extra_params:\n",
        "        if getattr(hparams, p, None):\n",
        "            if not hasattr(config, p) and not hasattr(config, equivalent_param[p]):\n",
        "                logger.info(\"config doesn't have a `{}` attribute\".format(p))\n",
        "                delattr(hparams, p)\n",
        "                continue\n",
        "            set_p = p if hasattr(config, p) else equivalent_param[p]\n",
        "            setattr(config, set_p, getattr(hparams, p))\n",
        "            delattr(hparams, p)\n",
        "    return hparams, config"
      ],
      "metadata": {
        "id": "3Jaf2zD2tErY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. \"callbacks_rag.py\""
      ],
      "metadata": {
        "id": "CnP3hVsysu2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.utilities import rank_zero_only\n",
        "\n",
        "#from utils_rag import save_json\n",
        "\n",
        "\n",
        "def count_trainable_parameters(model):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "    return params\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def get_checkpoint_callback(output_dir, metric):\n",
        "    \"\"\"Saves the best model by validation EM score.\"\"\"\n",
        "    if metric == \"rouge2\":\n",
        "        exp = \"{val_avg_rouge2:.4f}-{step_count}\"\n",
        "    elif metric == \"bleu\":\n",
        "        exp = \"{val_avg_bleu:.4f}-{step_count}\"\n",
        "    elif metric == \"em\":\n",
        "        exp = \"{val_avg_em:.4f}-{step_count}\"\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            f\"seq2seq callbacks only support rouge2 and bleu, got {metric}, You can make your own by adding to this function.\"\n",
        "        )\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        dirpath=output_dir,\n",
        "        filename=exp,\n",
        "        monitor=f\"val_{metric}\",\n",
        "        mode=\"max\",\n",
        "        save_top_k=3,\n",
        "        every_n_epochs=1,  # maybe save a checkpoint every time val is run, not just end of epoch.\n",
        "    )\n",
        "    return checkpoint_callback\n",
        "\n",
        "\n",
        "def get_early_stopping_callback(metric, patience):\n",
        "    return EarlyStopping(\n",
        "        monitor=f\"val_{metric}\",  # does this need avg?\n",
        "        mode=\"min\" if \"loss\" in metric else \"max\",\n",
        "        patience=patience,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "\n",
        "class Seq2SeqLoggingCallback(pl.Callback):\n",
        "    def on_batch_end(self, trainer, pl_module):\n",
        "        lrs = {f\"lr_group_{i}\": param[\"lr\"] for i, param in enumerate(pl_module.trainer.optimizers[0].param_groups)}\n",
        "        pl_module.logger.log_metrics(lrs)\n",
        "\n",
        "    @rank_zero_only\n",
        "    def _write_logs(\n",
        "        self, trainer: pl.Trainer, pl_module: pl.LightningModule, type_path: str, save_generations=True\n",
        "    ) -> None:\n",
        "        logger.info(f\"***** {type_path} results at step {trainer.global_step:05d} *****\")\n",
        "        metrics = trainer.callback_metrics\n",
        "        trainer.logger.log_metrics({k: v for k, v in metrics.items() if k not in [\"log\", \"progress_bar\", \"preds\"]})\n",
        "        # Log results\n",
        "        od = Path(pl_module.hparams.output_dir)\n",
        "        if type_path == \"test\":\n",
        "            results_file = od / \"test_results.txt\"\n",
        "            generations_file = od / \"test_generations.txt\"\n",
        "        else:\n",
        "            # this never gets hit. I prefer not to save intermediate generations, and results are in metrics.json\n",
        "            # If people want this it will be easy enough to add back.\n",
        "            results_file = od / f\"{type_path}_results/{trainer.global_step:05d}.txt\"\n",
        "            generations_file = od / f\"{type_path}_generations/{trainer.global_step:05d}.txt\"\n",
        "            results_file.parent.mkdir(exist_ok=True)\n",
        "            generations_file.parent.mkdir(exist_ok=True)\n",
        "        with open(results_file, \"a+\") as writer:\n",
        "            for key in sorted(metrics):\n",
        "                if key in [\"log\", \"progress_bar\", \"preds\"]:\n",
        "                    continue\n",
        "                val = metrics[key]\n",
        "                if isinstance(val, torch.Tensor):\n",
        "                    val = val.item()\n",
        "                msg = f\"{key}: {val:.6f}\\n\"\n",
        "                writer.write(msg)\n",
        "\n",
        "        if not save_generations:\n",
        "            return\n",
        "\n",
        "        if \"preds\" in metrics:\n",
        "            content = \"\\n\".join(metrics[\"preds\"])\n",
        "            generations_file.open(\"w+\").write(content)\n",
        "\n",
        "    @rank_zero_only\n",
        "    def on_train_start(self, trainer, pl_module):\n",
        "        try:\n",
        "            npars = pl_module.model.model.num_parameters()\n",
        "        except AttributeError:\n",
        "            npars = pl_module.model.num_parameters()\n",
        "\n",
        "        n_trainable_pars = count_trainable_parameters(pl_module)\n",
        "        # mp stands for million parameters\n",
        "        trainer.logger.log_metrics({\"n_params\": npars, \"mp\": npars / 1e6, \"grad_mp\": n_trainable_pars / 1e6})\n",
        "\n",
        "    @rank_zero_only\n",
        "    def on_test_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
        "        save_json(pl_module.metrics, pl_module.metrics_save_path)\n",
        "        return self._write_logs(trainer, pl_module, \"test\")\n",
        "\n",
        "    @rank_zero_only\n",
        "    def on_validation_end(self, trainer: pl.Trainer, pl_module):\n",
        "        save_json(pl_module.metrics, pl_module.metrics_save_path)\n",
        "        # Uncommenting this will save val generations\n",
        "        # return self._write_logs(trainer, pl_module, \"valid\")"
      ],
      "metadata": {
        "id": "b0RivfRRsxBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. \"lightning_base.py\""
      ],
      "metadata": {
        "id": "4VGe-HltiUcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.utilities import rank_zero_info\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModel,\n",
        "    AutoModelForPreTraining,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoModelForTokenClassification,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PretrainedConfig,\n",
        "    PreTrainedTokenizer,\n",
        ")\n",
        "from transformers.optimization import (\n",
        "    Adafactor,\n",
        "    get_cosine_schedule_with_warmup,\n",
        "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
        "    get_linear_schedule_with_warmup,\n",
        "    get_polynomial_decay_schedule_with_warmup,\n",
        ")\n",
        "from transformers.utils.versions import require_version\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "require_version(\"pytorch_lightning>=1.0.4\")\n",
        "\n",
        "MODEL_MODES = {\n",
        "    \"base\": AutoModel,\n",
        "    \"sequence-classification\": AutoModelForSequenceClassification,\n",
        "    \"question-answering\": AutoModelForQuestionAnswering,\n",
        "    \"pretraining\": AutoModelForPreTraining,\n",
        "    \"token-classification\": AutoModelForTokenClassification,\n",
        "    \"language-modeling\": AutoModelWithLMHead,\n",
        "    \"summarization\": AutoModelForSeq2SeqLM,\n",
        "    \"translation\": AutoModelForSeq2SeqLM,\n",
        "}\n",
        "\n",
        "\n",
        "# update this and the import above to support new schedulers from transformers.optimization\n",
        "arg_to_scheduler = {\n",
        "    \"linear\": get_linear_schedule_with_warmup,\n",
        "    \"cosine\": get_cosine_schedule_with_warmup,\n",
        "    \"cosine_w_restarts\": get_cosine_with_hard_restarts_schedule_with_warmup,\n",
        "    \"polynomial\": get_polynomial_decay_schedule_with_warmup,\n",
        "    # '': get_constant_schedule,             # not supported for now\n",
        "    # '': get_constant_schedule_with_warmup, # not supported for now\n",
        "}\n",
        "arg_to_scheduler_choices = sorted(arg_to_scheduler.keys())\n",
        "arg_to_scheduler_metavar = \"{\" + \", \".join(arg_to_scheduler_choices) + \"}\"\n"
      ],
      "metadata": {
        "id": "q2e7Far8iXBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.1. Class: BaseTransformer"
      ],
      "metadata": {
        "id": "v-IB-YQBm_1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseTransformer(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hparams: argparse.Namespace,\n",
        "        num_labels=None,\n",
        "        mode=\"base\",\n",
        "        config=None,\n",
        "        tokenizer=None,\n",
        "        model=None,\n",
        "        **config_kwargs\n",
        "    ):\n",
        "        \"\"\"Initialize a model, tokenizer and config.\"\"\"\n",
        "        super().__init__()\n",
        "        # TODO: move to self.save_hyperparameters()\n",
        "        # self.save_hyperparameters()\n",
        "        # can also expand arguments into trainer signature for easier reading\n",
        "\n",
        "        self.save_hyperparameters(hparams)\n",
        "        self.step_count = 0\n",
        "        self.output_dir = Path(self.hparams.output_dir)\n",
        "        cache_dir = self.hparams.cache_dir if self.hparams.cache_dir else None\n",
        "        if config is None:\n",
        "            self.config = AutoConfig.from_pretrained(\n",
        "                self.hparams.config_name if self.hparams.config_name else self.hparams.model_name_or_path,\n",
        "                **({\"num_labels\": num_labels} if num_labels is not None else {}),\n",
        "                cache_dir=cache_dir,\n",
        "                **config_kwargs,\n",
        "            )\n",
        "        else:\n",
        "            self.config: PretrainedConfig = config\n",
        "\n",
        "        extra_model_params = (\"encoder_layerdrop\", \"decoder_layerdrop\", \"dropout\", \"attention_dropout\")\n",
        "        for p in extra_model_params:\n",
        "            if getattr(self.hparams, p, None):\n",
        "                assert hasattr(self.config, p), f\"model config doesn't have a `{p}` attribute\"\n",
        "                setattr(self.config, p, getattr(self.hparams, p))\n",
        "\n",
        "        if tokenizer is None:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "                self.hparams.tokenizer_name if self.hparams.tokenizer_name else self.hparams.model_name_or_path,\n",
        "                cache_dir=cache_dir,\n",
        "            )\n",
        "        else:\n",
        "            self.tokenizer: PreTrainedTokenizer = tokenizer\n",
        "        self.model_type = MODEL_MODES[mode]\n",
        "        if model is None:\n",
        "            self.model = self.model_type.from_pretrained(\n",
        "                self.hparams.model_name_or_path,\n",
        "                from_tf=bool(\".ckpt\" in self.hparams.model_name_or_path),\n",
        "                config=self.config,\n",
        "                cache_dir=cache_dir,\n",
        "            )\n",
        "        else:\n",
        "            self.model = model\n",
        "\n",
        "    def load_hf_checkpoint(self, *args, **kwargs):\n",
        "        self.model = self.model_type.from_pretrained(*args, **kwargs)\n",
        "\n",
        "    def get_lr_scheduler(self):\n",
        "        get_schedule_func = arg_to_scheduler[self.hparams.lr_scheduler]\n",
        "        scheduler = get_schedule_func(\n",
        "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.total_steps()\n",
        "        )\n",
        "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
        "        return scheduler\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"\n",
        "        model = self.model\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.hparams.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "        if self.hparams.adafactor:\n",
        "            optimizer = Adafactor(\n",
        "                optimizer_grouped_parameters, lr=self.hparams.learning_rate, scale_parameter=False, relative_step=False\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            optimizer = AdamW(\n",
        "                optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon\n",
        "            )\n",
        "        self.opt = optimizer\n",
        "\n",
        "        scheduler = self.get_lr_scheduler()\n",
        "\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def test_step(self, batch, batch_nb):\n",
        "        return self.validation_step(batch, batch_nb)\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        return self.validation_end(outputs)\n",
        "\n",
        "    def total_steps(self) -> int:\n",
        "        \"\"\"The number of total training steps that will be run. Used for lr scheduler purposes.\"\"\"\n",
        "        num_devices = max(1, self.hparams.gpus)  # TODO: consider num_tpu_cores\n",
        "        effective_batch_size = self.hparams.train_batch_size * self.hparams.accumulate_grad_batches * num_devices\n",
        "        return (self.dataset_size / effective_batch_size) * self.hparams.max_epochs\n",
        "\n",
        "    def setup(self, stage):\n",
        "        if stage == \"test\":\n",
        "            self.dataset_size = len(self.test_dataloader().dataset)\n",
        "        else:\n",
        "            self.train_loader = self.get_dataloader(\"train\", self.hparams.train_batch_size, shuffle=True)\n",
        "            self.dataset_size = len(self.train_dataloader().dataset)\n",
        "\n",
        "    def get_dataloader(self, type_path: str, batch_size: int, shuffle: bool = False):\n",
        "        raise NotImplementedError(\"You must implement this for your task\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.get_dataloader(\"dev\", self.hparams.eval_batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.get_dataloader(\"test\", self.hparams.eval_batch_size, shuffle=False)\n",
        "\n",
        "    def _feature_file(self, mode):\n",
        "        return os.path.join(\n",
        "            self.hparams.data_dir,\n",
        "            \"cached_{}_{}_{}\".format(\n",
        "                mode,\n",
        "                list(filter(None, self.hparams.model_name_or_path.split(\"/\"))).pop(),\n",
        "                str(self.hparams.max_seq_length),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    @pl.utilities.rank_zero_only\n",
        "    def on_save_checkpoint(self, checkpoint: Dict[str, Any]) -> None:\n",
        "        save_path = self.output_dir.joinpath(\"best_tfmr\")\n",
        "        self.model.config.save_step = self.step_count\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n"
      ],
      "metadata": {
        "id": "z3awUqdWiejJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class InitCallback(pl.Callback):\n",
        "    # This method is better that using a custom DDP plugging with the latest pytorch-lightning (@shamanez)\n",
        "    def on_sanity_check_start(self, trainer, pl_module):\n",
        "        \n",
        "        # https://github.com/huggingface/transformers/master/src/transformers/models/rag/retrieval_rag.py#L458\n",
        "        pl_module.model.rag.retriever.init_retrieval()  # better to use hook functions.\n",
        "\n"
      ],
      "metadata": {
        "id": "B4DmWlkFicjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "    def on_batch_end(self, trainer, pl_module):\n",
        "        lr_scheduler = trainer.lr_schedulers[0][\"scheduler\"]\n",
        "        lrs = {f\"lr_group_{i}\": lr for i, lr in enumerate(lr_scheduler.get_lr())}\n",
        "        pl_module.logger.log_metrics(lrs)\n",
        "\n",
        "    def on_validation_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
        "        rank_zero_info(\"***** Validation results *****\")\n",
        "        metrics = trainer.callback_metrics\n",
        "        # Log results\n",
        "        for key in sorted(metrics):\n",
        "            if key not in [\"log\", \"progress_bar\"]:\n",
        "                rank_zero_info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "    def on_test_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
        "        rank_zero_info(\"***** Test results *****\")\n",
        "        metrics = trainer.callback_metrics\n",
        "        # Log and save results to file\n",
        "        output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
        "        with open(output_test_results_file, \"w\") as writer:\n",
        "            for key in sorted(metrics):\n",
        "                if key not in [\"log\", \"progress_bar\"]:\n",
        "                    rank_zero_info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                    writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n"
      ],
      "metadata": {
        "id": "GnIReusQibi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3.2. \"generic_train\""
      ],
      "metadata": {
        "id": "-L5pjfTPnUeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generic_train(\n",
        "    model: BaseTransformer,\n",
        "    args: argparse.Namespace,\n",
        "    early_stopping_callback=None,\n",
        "    logger=True,  # can pass WandbLogger() here\n",
        "    custom_ddp_plugin=None,\n",
        "    extra_callbacks=[],\n",
        "    checkpoint_callback=None,\n",
        "    logging_callback=None,\n",
        "    **extra_train_kwargs\n",
        "):\n",
        "    pl.seed_everything(args.seed)\n",
        "\n",
        "    # init model\n",
        "    odir = Path(model.hparams.output_dir)\n",
        "    odir.mkdir(exist_ok=True)\n",
        "\n",
        "    # add custom checkpoints\n",
        "    if checkpoint_callback is None:\n",
        "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "            filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=1\n",
        "        )\n",
        "    if early_stopping_callback:\n",
        "        extra_callbacks.append(early_stopping_callback)\n",
        "    if logging_callback is None:\n",
        "        logging_callback = LoggingCallback()\n",
        "\n",
        "    train_params = {}\n",
        "\n",
        "    # TODO: remove with PyTorch 1.6 since pl uses native amp\n",
        "    if args.fp16:\n",
        "        train_params[\"precision\"] = 16\n",
        "        # train_params[\"amp_level\"] = args.fp16_opt_level\n",
        "\n",
        "    if args.gpus > 1:\n",
        "        train_params[\"accelerator\"] = \"auto\"  # \"ddp\"\n",
        "        train_params[\"strategy\"] = \"ddp\"\n",
        "\n",
        "    train_params[\"accumulate_grad_batches\"] = args.accumulate_grad_batches\n",
        "    train_params[\"profiler\"] = None  # extra_train_kwargs.get(\"profiler\", None) #get unwanted logs\n",
        "    train_params[\"devices\"] = \"auto\"\n",
        "\n",
        "    trainer = pl.Trainer.from_argparse_args(\n",
        "        args,\n",
        "        weights_summary=None,\n",
        "        # [Chris] - Trying to disable checkpointing to work around an issue with the validation metrics...\n",
        "        #callbacks=[logging_callback] + extra_callbacks + [checkpoint_callback] + [InitCallback()],\n",
        "        callbacks=[logging_callback] + extra_callbacks + [InitCallback()],\n",
        "        # plugins=[custom_ddp_plugin],\n",
        "        logger=logger,\n",
        "        **train_params,\n",
        "    )\n",
        "\n",
        "    if args.do_train:\n",
        "        trainer.fit(model)\n",
        "\n",
        "    return trainer\n"
      ],
      "metadata": {
        "id": "To3cr3FqiYm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. \"finetune_rag.py\""
      ],
      "metadata": {
        "id": "ZnWl5IXLQ1T2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are all standard libraries, plus `transformers`."
      ],
      "metadata": {
        "id": "EYbxoHJ3j6ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Finetuning script for RAG models. Adapted from examples.seq2seq.finetune.py\"\"\"\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "import torch.distributed as torch_distrib\n",
        "from pytorch_lightning.plugins.training_type import DDPPlugin\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    BartForConditionalGeneration,\n",
        "    BatchEncoding,\n",
        "    RagConfig,\n",
        "    RagSequenceForGeneration,\n",
        "    RagTokenForGeneration,\n",
        "    RagTokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        ")\n",
        "\n",
        "from transformers import logging as transformers_logging\n",
        "\n"
      ],
      "metadata": {
        "id": "ts4tToGaQ3Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [Chris] - Need to fake this variable. The expression below just gives '/'\n",
        "#__file__ = \"/content/finetune_rag.py\"\n",
        "\n",
        "# need the parent dir module\n",
        "#sys.path.insert(2, str(Path(__file__).resolve().parents[1]))\n",
        "\n",
        "sys.path.insert(2, '/')"
      ],
      "metadata": {
        "id": "LNOe6OOhkRBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up logging."
      ],
      "metadata": {
        "id": "mCCKaU3aT6ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "transformers_logging.set_verbosity_info()\n",
        "\n"
      ],
      "metadata": {
        "id": "abi8IYB0S-gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n"
      ],
      "metadata": {
        "id": "eDgUx4vkSLDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class: GenerativeQAModule"
      ],
      "metadata": {
        "id": "QUOjWC3JSGzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class is an example of a LightningModule, which is what you define in order to use the PyTorch Lightning Trainer.\n",
        "\n",
        "The documentation is here: https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html\n",
        "\n",
        "There are really two key functions here:\n",
        "\n",
        "**_step**\n",
        "* This performs a forward pass of the whole architecture and calculates the loss for the purpose of training.\n",
        "   * However, the real forward pass is implemented in `RagTokenForGeneration`-- there's very little actually here!\n",
        "\n",
        "**_generative_step**\n",
        "* This also runs through the whole architecture, but generates the final text output.\n",
        "\n",
        "These two operations are not the same--RAG does something different on the output when we're training it.\n"
      ],
      "metadata": {
        "id": "IfKfieo_vB4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RagRetriever\n",
        "\n",
        "class GenerativeQAModule(BaseTransformer):\n",
        "    mode = \"generative_qa\"\n",
        "    loss_names = [\"loss\"]\n",
        "    metric_names = [\"em\"]\n",
        "    val_metric = \"em\"\n",
        "\n",
        "\n",
        "    def __init__(self, hparams, config, tokenizer, model, **kwargs):\n",
        "        \n",
        "        # when loading from a pytorch lightning checkpoint, hparams are passed as dict\n",
        "        if isinstance(hparams, dict):\n",
        "            hparams = AttrDict(hparams)\n",
        "\n",
        "        # Presumably this function handles the self.model = model step.\n",
        "        super().__init__(hparams, config=config, tokenizer=tokenizer, model=model)\n",
        "        \n",
        "        \n",
        "        self.output_dir = Path(self.hparams.output_dir)\n",
        "        self.metrics_save_path = Path(self.output_dir) / \"metrics.json\"\n",
        "        self.hparams_save_path = Path(self.output_dir) / \"hparams.pkl\"\n",
        "        pickle_save(self.hparams, self.hparams_save_path)\n",
        "        self.step_count = 0\n",
        "        self.metrics = defaultdict(list)\n",
        "\n",
        "        self.dataset_kwargs: dict = dict(\n",
        "            data_dir=self.hparams.data_dir,\n",
        "            max_source_length=self.hparams.max_source_length,\n",
        "            #prefix = prefix or \"\",\n",
        "            prefix = \"\"\n",
        "        )\n",
        "\n",
        "        n_observations_per_split = {\n",
        "            \"train\": self.hparams.n_train,\n",
        "            \"val\": self.hparams.n_val,\n",
        "            \"test\": self.hparams.n_test,\n",
        "        }\n",
        "\n",
        "        self.n_obs = {k: v if v >= 0 else None for k, v in n_observations_per_split.items()}\n",
        "\n",
        "        self.target_lens = {\n",
        "            \"train\": self.hparams.max_target_length,\n",
        "            \"val\": self.hparams.val_max_target_length,\n",
        "            \"test\": self.hparams.test_max_target_length,\n",
        "        }\n",
        "        assert self.target_lens[\"train\"] <= self.target_lens[\"val\"], f\"target_lens: {self.target_lens}\"\n",
        "        assert self.target_lens[\"train\"] <= self.target_lens[\"test\"], f\"target_lens: {self.target_lens}\"\n",
        "\n",
        "        # [Chris] - Removing dependencies to git.\n",
        "        #self.hparams.git_sha = get_git_info()[\"repo_sha\"]\n",
        "        \n",
        "        self.num_workers = hparams.num_workers\n",
        "        self.distributed_port = self.hparams.distributed_port\n",
        "\n",
        "        # For single GPU training, init_ddp_connection is not called.\n",
        "        # So we need to initialize the retrievers here.\n",
        "        if False:\n",
        "            if hparams.gpus <= 1:\n",
        "                if hparams.distributed_retriever == \"ray\":\n",
        "                    self.model.retriever.init_retrieval()\n",
        "                elif hparams.distributed_retriever == \"pytorch\":\n",
        "                    self.model.retriever.init_retrieval(self.distributed_port)\n",
        "\n",
        "            self.distributed_retriever = hparams.distributed_retriever\n",
        "\n",
        "\n",
        "    # ======== forward ========\n",
        "    # Docs: \"Use for inference only (separate from training_step)\"\n",
        "    #\n",
        "    def forward(self, input_ids, **kwargs):\n",
        "        return self.model(input_ids, **kwargs)\n",
        "\n",
        "\n",
        "    # ======== ids_to_clean_text ========\n",
        "    # TODO - I'm unclear on whether this is intended to be called on a single\n",
        "    #        output sequence or a batch...\n",
        "    # \n",
        "    def ids_to_clean_text(self, generated_ids: List[int]):\n",
        "        \n",
        "        # self.tokenizer is of type RagTokenizer.\n",
        "        # RagTokenizer.batch_decode just calls down to `BartTokenizerFast.batch_decode`.\n",
        "        gen_text = self.tokenizer.batch_decode(\n",
        "            generated_ids, \n",
        "            skip_special_tokens=True, \n",
        "            clean_up_tokenization_spaces=True\n",
        "        )\n",
        "        \n",
        "        # lmap will call 'strip' on each element of 'gen_text', and returns\n",
        "        # the results as a list.\n",
        "        return lmap(str.strip, gen_text)\n",
        "\n",
        "\n",
        "    # ======== _step ========\n",
        "    # [Chris] - This doesn't appear to be lightning...\n",
        "    # Both '_generative_step' and 'training_step' call this.\n",
        "    # \n",
        "    # 1. 'training_step' just calls this and adds some logging afterwards.\n",
        "    # \n",
        "    # 2. '_generative_step' (which is the implementation of both validation and \n",
        "    #    test), \n",
        "    #  \n",
        "    def _step(self, batch: dict) -> Tuple:\n",
        "        source_ids, source_mask, target_ids = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"decoder_input_ids\"]\n",
        "\n",
        "        rag_kwargs = {}\n",
        "        \n",
        "        generator = self.model.rag.generator\n",
        "        \n",
        "        decoder_input_ids = target_ids\n",
        "        \n",
        "        lm_labels = decoder_input_ids\n",
        "        rag_kwargs[\"reduce_loss\"] = True\n",
        "\n",
        "        assert decoder_input_ids is not None\n",
        "\n",
        "        outputs = self(\n",
        "            source_ids,\n",
        "            attention_mask=source_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            use_cache=False,\n",
        "            labels=lm_labels,\n",
        "            **rag_kwargs,\n",
        "        )\n",
        "\n",
        "        loss = outputs[\"loss\"]\n",
        "        return (loss,)\n",
        "\n",
        "    @property\n",
        "    def pad(self) -> int:\n",
        "        raise NotImplementedError(\"pad not implemented\")\n",
        "\n",
        "    # ======== training_step ========\n",
        "    # Lightning function. Doc: \"the complete training loop\"\n",
        "    def training_step(self, batch, batch_idx) -> Dict:\n",
        "        loss_tensors = self._step(batch)\n",
        "\n",
        "        logs = {name: loss.detach() for name, loss in zip(self.loss_names, loss_tensors)}\n",
        "        # tokens per batch\n",
        "        tgt_pad_token_id = (\n",
        "            self.tokenizer.generator.pad_token_id\n",
        "            if isinstance(self.tokenizer, RagTokenizer)\n",
        "            else self.tokenizer.pad_token_id\n",
        "        )\n",
        "        src_pad_token_id = (\n",
        "            self.tokenizer.question_encoder.pad_token_id\n",
        "            if isinstance(self.tokenizer, RagTokenizer)\n",
        "            else self.tokenizer.pad_token_id\n",
        "        )\n",
        "        logs[\"tpb\"] = (\n",
        "            batch[\"input_ids\"].ne(src_pad_token_id).sum() + batch[\"decoder_input_ids\"].ne(tgt_pad_token_id).sum()\n",
        "        )\n",
        "\n",
        "        return {\"loss\": loss_tensors[0], \"log\": logs}\n",
        "\n",
        "    # ======== validation_step ========\n",
        "    # Ligntning function. Doc: \"the complete validation loop\"\n",
        "    def validation_step(self, batch, batch_idx) -> Dict:\n",
        "        return self._generative_step(batch)\n",
        "\n",
        "    # ======== validation_epoch_end ========\n",
        "    #\n",
        "    def validation_epoch_end(self, outputs, prefix=\"val\") -> Dict:\n",
        "        self.step_count += 1\n",
        "        losses = {k: torch.stack([x[k] for x in outputs]).mean() for k in self.loss_names}\n",
        "        loss = losses[\"loss\"]\n",
        "        gen_metrics = {\n",
        "            k: np.array([x[k] for x in outputs]).mean() for k in self.metric_names + [\"gen_time\", \"gen_len\"]\n",
        "        }\n",
        "        metrics_tensor: torch.FloatTensor = torch.tensor(gen_metrics[self.val_metric]).type_as(loss)\n",
        "        gen_metrics.update({k: v.item() for k, v in losses.items()})\n",
        "\n",
        "        # fix for https://github.com/PyTorchLightning/pytorch-lightning/issues/2424\n",
        "        if dist.is_initialized():\n",
        "            dist.all_reduce(metrics_tensor, op=dist.ReduceOp.SUM)\n",
        "            metrics_tensor = metrics_tensor / dist.get_world_size()\n",
        "            gen_metrics.update({self.val_metric: metrics_tensor.item()})\n",
        "\n",
        "        losses.update(gen_metrics)\n",
        "        metrics = {f\"{prefix}_avg_{k}\": x for k, x in losses.items()}\n",
        "        metrics[\"step_count\"] = self.step_count\n",
        "        self.save_metrics(metrics, prefix)  # writes to self.metrics_save_path\n",
        "        preds = flatten_list([x[\"preds\"] for x in outputs])\n",
        "        return {\"log\": metrics, \"preds\": preds, f\"{prefix}_loss\": loss, f\"{prefix}_{self.val_metric}\": metrics_tensor}\n",
        "\n",
        "    def save_metrics(self, latest_metrics, type_path) -> None:\n",
        "        self.metrics[type_path].append(latest_metrics)\n",
        "        save_json(self.metrics, self.metrics_save_path)\n",
        "\n",
        "    # ======== _generative_step ========\n",
        "    # Non-lightning.\n",
        "    # 'validation_step' and 'test_step' simply pass down to this funciton. \n",
        "    #\n",
        "    def _generative_step(self, batch: dict) -> dict:\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        batch = BatchEncoding(batch).to(device=self.model.device)\n",
        "        \n",
        "        # Run the inputs through the entire framework! \n",
        "        generated_ids = self.model.generate(\n",
        "            batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            do_deduplication=False,  # rag specific parameter\n",
        "            use_cache=True,\n",
        "            min_length=1,\n",
        "            max_length=self.target_lens[\"val\"],\n",
        "        )\n",
        "\n",
        "        gen_time = (time.time() - start_time) / batch[\"input_ids\"].shape[0]\n",
        "        \n",
        "        # Turn the generated token IDs into a list of token strings.\n",
        "        preds: List[str] = self.ids_to_clean_text(generated_ids)\n",
        "        \n",
        "        # Also get the list of correct IDs (again, as a list of token strings).\n",
        "        target: List[str] = self.ids_to_clean_text(batch[\"decoder_input_ids\"])\n",
        "\n",
        "        # Call an iteration of the training loop just to calculate the loss.\n",
        "        loss_tensors = self._step(batch)\n",
        "        base_metrics = {name: loss for name, loss in zip(self.loss_names, loss_tensors)}\n",
        "        \n",
        "        # Score the output! Exact match is simply the number of tokens which\n",
        "        # match (and it's position dependent!)\n",
        "        gen_metrics: Dict = calculate_exact_match(preds, target)\n",
        "\n",
        "        summ_len = np.mean(lmap(len, generated_ids))\n",
        "        \n",
        "        base_metrics.update(gen_time=gen_time, gen_len=summ_len, preds=preds, target=target, **gen_metrics)\n",
        "        \n",
        "        return base_metrics\n",
        "\n",
        "    # ======== test_step ========\n",
        "    # Lightning function. Doc: \"the complete test loop\"\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self._generative_step(batch)\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        return self.validation_epoch_end(outputs, prefix=\"test\")\n",
        "\n",
        "    def get_dataset(self, type_path) -> Seq2SeqDataset:\n",
        "        n_obs = self.n_obs[type_path]\n",
        "        max_target_length = self.target_lens[type_path]\n",
        "        dataset = Seq2SeqDataset(\n",
        "            self.tokenizer,\n",
        "            type_path=type_path,\n",
        "            n_obs=n_obs,\n",
        "            max_target_length=max_target_length,\n",
        "            **self.dataset_kwargs,\n",
        "        )\n",
        "        return dataset\n",
        "\n",
        "    def get_dataloader(self, type_path: str, batch_size: int, shuffle: bool = False) -> DataLoader:\n",
        "        dataset = self.get_dataset(type_path)\n",
        "\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            collate_fn=dataset.collate_fn,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=self.num_workers,\n",
        "        )\n",
        "        return dataloader\n",
        "\n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        dataloader = self.get_dataloader(\"train\", batch_size=self.hparams.train_batch_size, shuffle=True)\n",
        "        return dataloader\n",
        "\n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader(\"val\", batch_size=self.hparams.eval_batch_size)\n",
        "\n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        return self.get_dataloader(\"test\", batch_size=self.hparams.eval_batch_size)\n",
        "\n",
        "    @pl.utilities.rank_zero_only\n",
        "    def on_save_checkpoint(self, checkpoint: Dict[str, Any]) -> None:\n",
        "        save_path = self.output_dir.joinpath(\"checkpoint{}\".format(self.step_count))\n",
        "        self.model.config.save_step = self.step_count\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vrs27Lq5SEvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5. Argument Definitions"
      ],
      "metadata": {
        "id": "iVSAOAl0orj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an ArgumentParser object.\n",
        "parser = argparse.ArgumentParser()"
      ],
      "metadata": {
        "id": "TsS-nO5dpJi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some standard arguments for PyTorch Lightning?\n",
        "parser = pl.Trainer.add_argparse_args(parser)\n",
        "\n",
        "# Pytorch Lightning Profiler\n",
        "parser.add_argument(\n",
        "    \"--profile\",\n",
        "    action=\"store_true\",\n",
        "    help=\"If True, use pytorch_lightning.profiler.AdvancedProfiler to profile the Trainer.\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DRfqwj0qPlV",
        "outputId": "a62e516b-ba64-4538-c142-2858a23889a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--profile'], dest='profile', nargs=0, const=True, default=False, type=None, choices=None, help='If True, use pytorch_lightning.profiler.AdvancedProfiler to profile the Trainer.', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some of the arguments require this \"root_dir\" parameter.\n",
        "root_dir = os.getcwd()"
      ],
      "metadata": {
        "id": "OLjr_1xmqUUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BaseTransformer --> add_model_specific_args**"
      ],
      "metadata": {
        "id": "mikhprjGo0qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - Needs arguments: parser, root_dir\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--model_name_or_path\",\n",
        "    default=None,\n",
        "    type=str,\n",
        "    required=True,\n",
        "    help=\"Path to pretrained model or model identifier from huggingface.co/models\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--config_name\", default=\"\", type=str, help=\"Pretrained config name or path if not the same as model_name\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--tokenizer_name\",\n",
        "    default=None,\n",
        "    type=str,\n",
        "    help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--cache_dir\",\n",
        "    default=\"\",\n",
        "    type=str,\n",
        "    help=\"Where do you want to store the pre-trained models downloaded from huggingface.co\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--encoder_layerdrop\",\n",
        "    type=float,\n",
        "    help=\"Encoder layer dropout probability (Optional). Goes into model.config\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--decoder_layerdrop\",\n",
        "    type=float,\n",
        "    help=\"Decoder layer dropout probability (Optional). Goes into model.config\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--dropout\",\n",
        "    type=float,\n",
        "    help=\"Dropout probability (Optional). Goes into model.config\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--attention_dropout\",\n",
        "    type=float,\n",
        "    help=\"Attention dropout probability (Optional). Goes into model.config\",\n",
        ")\n",
        "parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "parser.add_argument(\n",
        "    \"--lr_scheduler\",\n",
        "    default=\"linear\",\n",
        "    choices=arg_to_scheduler_choices,\n",
        "    metavar=arg_to_scheduler_metavar,\n",
        "    type=str,\n",
        "    help=\"Learning rate scheduler\",\n",
        ")\n",
        "parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
        "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "parser.add_argument(\"--num_workers\", default=4, type=int, help=\"kwarg passed to DataLoader\")\n",
        "parser.add_argument(\"--num_train_epochs\", dest=\"max_epochs\", default=3, type=int)\n",
        "parser.add_argument(\"--train_batch_size\", default=32, type=int)\n",
        "parser.add_argument(\"--eval_batch_size\", default=32, type=int)\n",
        "parser.add_argument(\"--adafactor\", action=\"store_true\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-GqmMg5otZc",
        "outputId": "8d7c755a-5fe1-456c-9428-a3eedba7a645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--adafactor'], dest='adafactor', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**add_generic_args**"
      ],
      "metadata": {
        "id": "NDJv2wfypxus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  To allow all pl args uncomment the following line\n",
        "#  parser = pl.Trainer.add_argparse_args(parser)\n",
        "parser.add_argument(\n",
        "    \"--output_dir\",\n",
        "    default=None,\n",
        "    type=str,\n",
        "    required=True,\n",
        "    help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--fp16\",\n",
        "    action=\"store_true\",\n",
        "    help=\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--fp16_opt_level\",\n",
        "    type=str,\n",
        "    default=\"O2\",\n",
        "    help=\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
        "    \"See details at https://nvidia.github.io/apex/amp.html\",\n",
        ")\n",
        "parser.add_argument(\"--n_tpu_cores\", dest=\"tpu_cores\", type=int)\n",
        "parser.add_argument(\"--max_grad_norm\", dest=\"gradient_clip_val\", default=1.0, type=float, help=\"Max gradient norm\")\n",
        "parser.add_argument(\"--do_train\", action=\"store_true\", help=\"Whether to run training.\")\n",
        "parser.add_argument(\"--do_predict\", action=\"store_true\", help=\"Whether to run predictions on the test set.\")\n",
        "parser.add_argument(\n",
        "    \"--gradient_accumulation_steps\",\n",
        "    dest=\"accumulate_grad_batches\",\n",
        "    type=int,\n",
        "    default=1,\n",
        "    help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        ")\n",
        "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "parser.add_argument(\n",
        "    \"--data_dir\",\n",
        "    default=None,\n",
        "    type=str,\n",
        "    required=True,\n",
        "    help=\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\",\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu-ErqKVpuin",
        "outputId": "6d258b43-eded-4857-9ff0-a2fa82a4bfd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--data_dir'], dest='data_dir', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='The input data dir. Should contain the training files for the CoNLL-2003 NER task.', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GenerativeQAModel --> add_model_specific_args**"
      ],
      "metadata": {
        "id": "h0m0UCa5pWak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument(\n",
        "    \"--max_source_length\",\n",
        "    default=128,\n",
        "    type=int,\n",
        "    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "    \"than this will be truncated, sequences shorter will be padded.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--max_target_length\",\n",
        "    default=25,\n",
        "    type=int,\n",
        "    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "    \"than this will be truncated, sequences shorter will be padded.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--val_max_target_length\",\n",
        "    default=25,\n",
        "    type=int,\n",
        "    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "    \"than this will be truncated, sequences shorter will be padded.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--test_max_target_length\",\n",
        "    default=25,\n",
        "    type=int,\n",
        "    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "    \"than this will be truncated, sequences shorter will be padded.\",\n",
        ")\n",
        "parser.add_argument(\"--logger_name\", type=str, choices=[\"default\", \"wandb\", \"wandb_shared\"], default=\"default\")\n",
        "parser.add_argument(\"--n_train\", type=int, default=-1, required=False, help=\"# examples. -1 means use all.\")\n",
        "parser.add_argument(\"--n_val\", type=int, default=-1, required=False, help=\"# examples. -1 means use all.\")\n",
        "parser.add_argument(\"--n_test\", type=int, default=-1, required=False, help=\"# examples. -1 means use all.\")\n",
        "parser.add_argument(\"--label_smoothing\", type=float, default=0.0, required=False)\n",
        "parser.add_argument(\n",
        "    \"--prefix\",\n",
        "    type=str,\n",
        "    default=None,\n",
        "    help=\"Prefix added at the beginning of each text, typically used with T5-based models.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--early_stopping_patience\",\n",
        "    type=int,\n",
        "    default=-1,\n",
        "    required=False,\n",
        "    help=\"-1 means never early stop. early_stopping_patience is measured in validation checks, not epochs. So val_check_interval will effect it.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--distributed-port\", type=int, default=-1, required=False, help=\"Port number for distributed training.\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--model_type\",\n",
        "    choices=[\"rag_sequence\", \"rag_token\", \"bart\", \"t5\"],\n",
        "    type=str,\n",
        "    help=\"RAG model type: sequence or token, if none specified, the type is inferred from the model_name_or_path\",\n",
        ")\n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slx9mp-jpSXy",
        "outputId": "7503ff2a-3497-41ce-e7cd-ed79cf144093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--model_type'], dest='model_type', nargs=None, const=None, default=None, type=<class 'str'>, choices=['rag_sequence', 'rag_token', 'bart', 't5'], help='RAG model type: sequence or token, if none specified, the type is inferred from the model_name_or_path', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GenerativeQAModule --> add_retriever_specific_args**"
      ],
      "metadata": {
        "id": "ixMs3tqbp9Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument(\n",
        "    \"--index_name\",\n",
        "    type=str,\n",
        "    default=None,\n",
        "    help=\"Name of the index to use: 'hf' for a canonical dataset from the datasets library (default), 'custom' for a local index, or 'legacy' for the orignal one)\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--passages_path\",\n",
        "    type=str,\n",
        "    default=None,\n",
        "    help=\"Path to the dataset of passages for custom index. More info about custom indexes in the RagRetriever documentation as well as in `examples/rag/use_own_knowledge_dataset.py`\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--index_path\",\n",
        "    type=str,\n",
        "    default=None,\n",
        "    help=\"Path to the faiss index for custom index. More info about custom indexes in the RagRetriever documentation as well as in `examples/rag/use_own_knowledge_dataset.py`\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--distributed_retriever\",\n",
        "    choices=[\"ray\", \"pytorch\"],\n",
        "    type=str,\n",
        "    default=\"pytorch\",\n",
        "    help=\"What implementation to use for distributed retriever? If \"\n",
        "    \"pytorch is selected, the index is loaded on training \"\n",
        "    \"worker 0, and torch.distributed is used to handle \"\n",
        "    \"communication between training worker 0, and the other \"\n",
        "    \"training workers. If ray is selected, the Ray library is \"\n",
        "    \"used to create load the index on separate processes, \"\n",
        "    \"and Ray handles the communication between the training \"\n",
        "    \"workers and the retrieval actors.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--use_dummy_dataset\",\n",
        "    type=bool,\n",
        "    default=False,\n",
        "    help=\"Whether to use the dummy version of the dataset index. More info about custom indexes in the RagRetriever documentation as well as in `examples/rag/use_own_knowledge_dataset.py`\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VoFJCb1pbLX",
        "outputId": "2b4d832e-e220-4d9d-8d6a-e6240975199f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--use_dummy_dataset'], dest='use_dummy_dataset', nargs=None, const=None, default=False, type=<class 'bool'>, choices=None, help='Whether to use the dummy version of the dataset index. More info about custom indexes in the RagRetriever documentation as well as in `examples/rag/use_own_knowledge_dataset.py`', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ray-specific arguments (unused)"
      ],
      "metadata": {
        "id": "9nutGa3XqdTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if False:\n",
        "    def add_ray_specific_args(parser):\n",
        "        # Ray cluster address.\n",
        "        parser.add_argument(\n",
        "            \"--ray-address\",\n",
        "            default=\"auto\",\n",
        "            type=str,\n",
        "            help=\"The address of the Ray cluster to connect to. If not \"\n",
        "            \"specified, Ray will attempt to automatically detect the \"\n",
        "            \"cluster. Has no effect if pytorch is used as the distributed \"\n",
        "            \"retriever.\",\n",
        "        )\n",
        "        parser.add_argument(\n",
        "            \"--num_retrieval_workers\",\n",
        "            type=int,\n",
        "            default=1,\n",
        "            help=\"The number of retrieval actors to use when Ray is selected\"\n",
        "            \"for the distributed retriever. Has no effect when \"\n",
        "            \"distributed_retriever is set to pytorch.\",\n",
        "        )\n",
        "        return parser"
      ],
      "metadata": {
        "id": "NmTDuQa3qCL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S3. Setup Model"
      ],
      "metadata": {
        "id": "Oo8NY-U7RGA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3.1. Set Script Arguments"
      ],
      "metadata": {
        "id": "6kcePvt8e6hS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the arguments in the code rather than with a command line parser."
      ],
      "metadata": {
        "id": "eYqWAkn0RH8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.argv = ['./test_argv.py', \n",
        "            '--data_dir', './data', \n",
        "            '--output_dir', './output', \n",
        "            '--model_name_or_path', 'facebook/rag-token-base', \n",
        "            '--model_type', 'rag_token', \n",
        "            '--use_dummy_dataset', 'True', \n",
        "            '--fp16', \n",
        "            '--gpus', '1',\n",
        "            '--train_batch_size', '1',\n",
        "            '--accumulate_grad_batches', '1',\n",
        "            '--max_epochs', '3',\n",
        "            '--enable_checkpointing', 'False',\n",
        "            '--checkpoint_callback', 'False'] #TODO - Lightning throws an error when trying to checkpoint because the 'em' metric is not being returned...\n",
        "\n",
        "#print(sys.argv)"
      ],
      "metadata": {
        "id": "HymsjsFqUfjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse the command line arguments.\n"
      ],
      "metadata": {
        "id": "SziUCx5aRFWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = parser.parse_args()\n",
        "\n",
        "args.actor_handles = []"
      ],
      "metadata": {
        "id": "FBMRjhEhR87W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.enable_checkpointing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WioDHe49pPL-",
        "outputId": "ab5e30ed-e5af-4a64-b72b-dc932dd7324d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the output directory."
      ],
      "metadata": {
        "id": "ozzoubfSVolo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Path(args.output_dir).mkdir(exist_ok=True)\n"
      ],
      "metadata": {
        "id": "33Y9RGcRVhLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Load Retriever & Generator"
      ],
      "metadata": {
        "id": "jAosJXvx8Sko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RagConfig**\n",
        "\n",
        "Might be interesting to see what this actually gets used for..."
      ],
      "metadata": {
        "id": "fk2AuKx38ZgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the config object        \n",
        "config = RagConfig.from_pretrained('facebook/rag-token-base')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ed051d0b9f8e46c4a44d2d20d6b15089",
            "30eddacf930b4e13a708246858896826",
            "8b25f9649c5f41f58c8c13032df9623f",
            "018245b234014e3aaf2d6ca0e11a7a7a",
            "ad376d7f2c4d4b4a9d2b9e6439eb2558",
            "f2f2efd62beb4a67a249f34637e465a5",
            "607c0d3fc64d4966b864d571d4f3606f",
            "582a60c5b3f34c229191c66d39c1cd31",
            "59ad5b03e84647089bc58e726db4a430",
            "9735d3260077490b9c1f7836dffab75b",
            "98cf08ca95d8451aae41449e7558571a"
          ]
        },
        "id": "on-8OpKJ6oNs",
        "outputId": "39421707-91c6-4de8-ce20-ca7f87cef8f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/facebook/rag-token-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpf8fr2gxs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.44k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed051d0b9f8e46c4a44d2d20d6b15089"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/f78a22d946ffd431f4614fef3a01644f384ab75473d1b6818dd3f8d86bc0e81c.9f453e8c75101a3b2565cc7fcf01d9ef0ab1784469dbdffce0027e1518210361\n",
            "creating metadata file for /root/.cache/huggingface/transformers/f78a22d946ffd431f4614fef3a01644f384ab75473d1b6818dd3f8d86bc0e81c.9f453e8c75101a3b2565cc7fcf01d9ef0ab1784469dbdffce0027e1518210361\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f78a22d946ffd431f4614fef3a01644f384ab75473d1b6818dd3f8d86bc0e81c.9f453e8c75101a3b2565cc7fcf01d9ef0ab1784469dbdffce0027e1518210361\n",
            "Model config RagConfig {\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartModel\",\n",
            "      \"BartForMaskedLM\",\n",
            "      \"BartForSequenceClassification\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": false,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": \" \",\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"exact\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"output_retrieved\": false,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.label_smoothing = args.label_smoothing\n",
        "\n",
        "# set extra_model_params for generator configs and load_model\n",
        "extra_model_params = (\"encoder_layerdrop\", \"decoder_layerdrop\", \"attention_dropout\", \"dropout\")\n",
        "\n",
        "args, config.generator = set_extra_model_params(extra_model_params, args, config.generator)\n"
      ],
      "metadata": {
        "id": "XBO1a4I37W1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RagRetriever**\n",
        "\n",
        "We'll create the retriever with our own custom dataset."
      ],
      "metadata": {
        "id": "JhLUxGg-8iJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the retriever\n",
        "retriever = RagRetriever.from_pretrained(\n",
        "    \n",
        "    \"facebook/rag-token-nq\", # The specific pre-trained model we'll use. \n",
        "\n",
        "    use_dummy_dataset = False, # The dummy dataset is reduced-size Wikipedia,\n",
        "\n",
        "    indexed_dataset = got_dataset, # Pass in our own GoT dataset!\n",
        "\n",
        "    index_name = \"embeddings\", # Specify the name of the FAISS index we created.\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8c842742905a4aa7ae1d0e8877bf2711",
            "d53084a265b04bb0b00ef46f3c89d457",
            "277e4bb5bf2243b195b04b243e2f327f",
            "90060639b5d24b4593b3cceed1887d56",
            "a43582b72ad047b881f07223905d56c5",
            "2653e7dc15fc459bb2182fac64568d5b",
            "bc411a19dbea42b8862944fb712693ab",
            "ed2fd6649f9a47cb93b5b20232b8eca0",
            "92e6a5bc7d6344a6b20cd8bb0a0ad6ec",
            "48665fa463604d7783f8d75b245fe166",
            "2242d2562feb477783fb9ca3d93cfe87",
            "35b76c8a357a4565930b7971604ebd82",
            "8668f4719e414cda971c7ff45071cbc1",
            "57449044342e4e7c97629f15e68a7404",
            "7b42b0bb68f4445b962de6c32bf92bd5",
            "becee9b002e3495ba0edb62478350d72",
            "b8657f7eeb594ce48b5271f17b2e9540",
            "c91eeddfcb274f7297a8bbf14292de4f",
            "e4622a76aa224d9585c7a8f4b0c5f4eb",
            "0c5c6c85d7bb4378b5ec05a9e502a8b0",
            "a792477e361c45b18e9213fd14456ede",
            "12233f931651460ebfee0aca16df27b1",
            "4828cfaca0f640cc859778376b31ddad",
            "602210ab08e04314a4dc279185363689",
            "878e62de3d824da39c6f795a7d9d48c2",
            "44fac7f298564ad79c835a3d89892966",
            "5c739719c8ee4752b7c106662fc3029d",
            "9b081c6c94a5490bb4b0db26cf2b1971",
            "8fada775a60244a09612c33b16f950af",
            "86454a255e8e4927b45744318325504a",
            "404c8f3e9955455bb14cc2361dbde876",
            "01671fecd42e4a8bb866fb461e4ee84e",
            "7228d7a24a364768bf461d9bccc41f99",
            "3b12357d4d86430c8d94b83c89f62e06",
            "30dcc9adda4e496c9334f916d127a4b0",
            "98575368190242a6ab1d41976684f9f5",
            "ac87185fe0b549a8a0bb2ab829b96cd5",
            "ca6fc6c975f748f88a5617fed702a563",
            "62dc23cb8df64b35927252a3be32461f",
            "616c9e6c7719448db3e64b5fe2474e94",
            "c57826a5f94c4504a6e7c8c3c60ffe7f",
            "3a3739825dee4466875ca2b509b35ef4",
            "8ca59c3ed67740cc9a9854b3a4ecb628",
            "e46eb86f9e7c4429a69152b52a06561b",
            "eb2e593bd4714e249f67f5d5413298b7",
            "eb9bcb967bde47e8893faa1a7261d940",
            "c00fa079e77741b797a483c0ad61d04e",
            "ef66d13030ee4ceb8181752fd2401378",
            "dfbec298822d476185ada22c9e2bd0a5",
            "2b1109097548434c9d2933c022dbed99",
            "51f8167da39d492d912f3252f3525994",
            "d88d54079d194bf1b3eb421405748dbe",
            "25e16435aaf14757b01fbf46889ac8b9",
            "b2e66a8dc47b4a6d9309f10588b0da62",
            "35ff2127697b49e19a9a5b00e85d8c2a",
            "ca8e10137a1f4d18a09f7348712b7590",
            "62ca5df71fc84444800e5a26ec9b8dc7",
            "14dc62b8297b4772ab2ea3337415fb06",
            "62db750c25a14eed8f61a13cd5c924a7",
            "d9573248081d426087b1d36b8bdb9840",
            "e73b565b91f24337bb1ec5c4b91b1f03",
            "0a55663c03164640a19ac761c3795141",
            "f21307a6052d47599d1876d193c9210a",
            "0db2585f2437423d9f5928135f19378c",
            "7aeb94c22bdf4879823ef861335c4f83",
            "b6ecf0e7038a4398a8680412950f4adf",
            "ee62f0c5091a4610b0c2130ceccd617f",
            "8a71fd5c770a4d99ac20b276396a0822",
            "21415d160462469c8b17b0f295f5051b",
            "fdef8f92395541c7b71979e19647256e",
            "7799913e4feb4b3b8b440cb052350e91",
            "d27e125bd13d40fa8f6cf43907438596",
            "cadf28a0fb1041739a9301ec25cb610c",
            "193e00edb52e43eea4ad5d1240eb31f6",
            "2acbf9b91a1e4fd794eb07f494847ccf",
            "23ee835693c54a95b0629188467bd376",
            "d4d10fed4abe4d1aa129ec4ee1a68394",
            "884cfdf03c6f43029c2114fd05b751c2",
            "504c0000b0274ca1bb03b60e699bf98b",
            "1953a69d81ba4e4e914299f7e3f41f57",
            "53959cf461214502b5dae27580715d1e",
            "e8654e1a8625478eab6f2f65a6b10836",
            "145b13cc26e84d58bc453d323da263d9",
            "56e07ae29d3f4c8fb4c520ccbf0cd4f9",
            "6229c919620a49e3af60dc79c522260d",
            "38b726cae5994a519c45fb631087f431",
            "941e67c0d85141028540d194f4c412e4",
            "28cc6d87a8274f1b8a1fd4fec9d451ad"
          ]
        },
        "id": "z1gzh50U7bin",
        "outputId": "1bc64ef8-c5e4-4d18-9721-0ee939145cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmph7dyifbc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c842742905a4aa7ae1d0e8877bf2711"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "creating metadata file for /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/bart/configuration_bart.py:180: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
            "  f\"Please make sure the config includes `forced_bos_token_id={self.bos_token_id}` in future versions. \"\n",
            "Model config RagConfig {\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"embeddings\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpzc2a502o\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35b76c8a357a4565930b7971604ebd82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/vocab.txt in cache at /root/.cache/huggingface/transformers/26cf899a0974235af1f84469ddd94d2ee83c803c23ecead93b511ce8a0744f5c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "creating metadata file for /root/.cache/huggingface/transformers/26cf899a0974235af1f84469ddd94d2ee83c803c23ecead93b511ce8a0744f5c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpshnhunyo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4828cfaca0f640cc859778376b31ddad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/d4df3c917efc1bf4cde9515ac4432cddf040d3ddacfad55c85445bc985f58ceb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "creating metadata file for /root/.cache/huggingface/transformers/d4df3c917efc1bf4cde9515ac4432cddf040d3ddacfad55c85445bc985f58ceb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmphfgif0_o\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b12357d4d86430c8d94b83c89f62e06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/445caa3aaff6c34b07acdff304db0c8468640baf1139f92c14270fc50cff2eb8.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
            "creating metadata file for /root/.cache/huggingface/transformers/445caa3aaff6c34b07acdff304db0c8468640baf1139f92c14270fc50cff2eb8.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/vocab.txt from cache at /root/.cache/huggingface/transformers/26cf899a0974235af1f84469ddd94d2ee83c803c23ecead93b511ce8a0744f5c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/d4df3c917efc1bf4cde9515ac4432cddf040d3ddacfad55c85445bc985f58ceb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/445caa3aaff6c34b07acdff304db0c8468640baf1139f92c14270fc50cff2eb8.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "Model config RagConfig {\n",
            "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "Model config RagConfig {\n",
            "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmptyjy7a54\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb2e593bd4714e249f67f5d5413298b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/vocab.json in cache at /root/.cache/huggingface/transformers/786598a0d343d4afb34b4f1ee17c14b58fb129abb0b3db386587bea52ffcfb11.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
            "creating metadata file for /root/.cache/huggingface/transformers/786598a0d343d4afb34b4f1ee17c14b58fb129abb0b3db386587bea52ffcfb11.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp0rotgalo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca8e10137a1f4d18a09f7348712b7590"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/merges.txt in cache at /root/.cache/huggingface/transformers/f5fdd0c4b41c985f791c9a230cdf051da1cf9480d84e0f5f617667760a24f50f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "creating metadata file for /root/.cache/huggingface/transformers/f5fdd0c4b41c985f791c9a230cdf051da1cf9480d84e0f5f617667760a24f50f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpg_s1087s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee62f0c5091a4610b0c2130ceccd617f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/73d054acda2f2b44f075a0d391ed392e6c53f78356bbf279581786ae35a79e4d.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
            "creating metadata file for /root/.cache/huggingface/transformers/73d054acda2f2b44f075a0d391ed392e6c53f78356bbf279581786ae35a79e4d.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpe15fouz9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "884cfdf03c6f43029c2114fd05b751c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/a2f0711fd4c199beaf3ff2626c4a723e107e79a8d065099a3d24e7aa361c0f18.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
            "creating metadata file for /root/.cache/huggingface/transformers/a2f0711fd4c199beaf3ff2626c4a723e107e79a8d065099a3d24e7aa361c0f18.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/vocab.json from cache at /root/.cache/huggingface/transformers/786598a0d343d4afb34b4f1ee17c14b58fb129abb0b3db386587bea52ffcfb11.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/merges.txt from cache at /root/.cache/huggingface/transformers/f5fdd0c4b41c985f791c9a230cdf051da1cf9480d84e0f5f617667760a24f50f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/73d054acda2f2b44f075a0d391ed392e6c53f78356bbf279581786ae35a79e4d.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a2f0711fd4c199beaf3ff2626c4a723e107e79a8d065099a3d24e7aa361c0f18.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "Model config RagConfig {\n",
            "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizer'.\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "Model config RagConfig {\n",
            "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizerFast'.\n",
            "initializing retrieval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RagTokenForGeneration** \n",
        "\n",
        "Load the generator!"
      ],
      "metadata": {
        "id": "6L1lsqO-8ox9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the model!\n",
        "model = RagTokenForGeneration.from_pretrained(\n",
        "    \"facebook/rag-token-nq\", \n",
        "    config = config, \n",
        "    retriever = retriever\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "b98f720ee2f5455a833cf0a07daa1ba7",
            "7412bb5a7e8f4d4989a063a1a6158198",
            "70083b97b9704666a6aee2ab42020cc5",
            "ca9f228ad0634b1db883e4c06293004a",
            "add8d28d6b564ed9b1165023a55758bd",
            "01d3a2065e614398999ea47af1db9edd",
            "5976b035c5884a6ca3c84a9ba82b051f",
            "0b65d8908de2483fb32cd20c65c11b1e",
            "0d31ff000ef944efb9abd24f8f5fe081",
            "d05ac948644648fb9a9e7b0573ccff46",
            "85d6f5a5ff804f1d9dac8673a2b3f783"
          ]
        },
        "id": "jsBMYsLO7V_U",
        "outputId": "9a76c88c-5e28-4fb4-9d6c-a6df2de0645f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "https://huggingface.co/facebook/rag-token-nq/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp6tiqvkw3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b98f720ee2f5455a833cf0a07daa1ba7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "storing https://huggingface.co/facebook/rag-token-nq/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/6288b70ae87b5989f6801120b25a2f6ccf2e88c2f622d94805717b5b043ff71b.bceb1ea6e95a1b39d0a717f315800a39b0847e5cdeeb42615fb498775f632ee6\n",
            "creating metadata file for /root/.cache/huggingface/transformers/6288b70ae87b5989f6801120b25a2f6ccf2e88c2f622d94805717b5b043ff71b.bceb1ea6e95a1b39d0a717f315800a39b0847e5cdeeb42615fb498775f632ee6\n",
            "loading weights file https://huggingface.co/facebook/rag-token-nq/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/6288b70ae87b5989f6801120b25a2f6ccf2e88c2f622d94805717b5b043ff71b.bceb1ea6e95a1b39d0a717f315800a39b0847e5cdeeb42615fb498775f632ee6\n",
            "Some weights of the model checkpoint at facebook/rag-token-nq were not used when initializing RagTokenForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.bias', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RagTokenForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RagTokenForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RagTokenForGeneration were not initialized from the model checkpoint at facebook/rag-token-nq and are newly initialized: ['rag.generator.lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RagTokenizer**"
      ],
      "metadata": {
        "id": "lRZOw3-S8tZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer!\n",
        "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id-FMaeY79zP",
        "outputId": "4ee3999e-54b3-46a5-f29e-58a6422df0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/bart/configuration_bart.py:180: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
            "  f\"Please make sure the config includes `forced_bos_token_id={self.bos_token_id}` in future versions. \"\n",
            "Model config RagConfig {\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/vocab.txt from cache at /root/.cache/huggingface/transformers/26cf899a0974235af1f84469ddd94d2ee83c803c23ecead93b511ce8a0744f5c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/d4df3c917efc1bf4cde9515ac4432cddf040d3ddacfad55c85445bc985f58ceb.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/question_encoder_tokenizer/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/445caa3aaff6c34b07acdff304db0c8468640baf1139f92c14270fc50cff2eb8.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "Model config RagConfig {\n",
            "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "Model config RagConfig {\n",
            "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/vocab.json from cache at /root/.cache/huggingface/transformers/786598a0d343d4afb34b4f1ee17c14b58fb129abb0b3db386587bea52ffcfb11.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/merges.txt from cache at /root/.cache/huggingface/transformers/f5fdd0c4b41c985f791c9a230cdf051da1cf9480d84e0f5f617667760a24f50f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/73d054acda2f2b44f075a0d391ed392e6c53f78356bbf279581786ae35a79e4d.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
            "loading file https://huggingface.co/facebook/rag-token-nq/resolve/main/generator_tokenizer/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a2f0711fd4c199beaf3ff2626c4a723e107e79a8d065099a3d24e7aa361c0f18.67d01b18f2079bd75eac0b2f2e7235768c7f26bd728e7a855a1c5acae01a91a8\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "Model config RagConfig {\n",
            "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizer'.\n",
            "loading configuration file https://huggingface.co/facebook/rag-token-nq/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6337b0203e20d15c98f5e500e1e673c74e71bb8617b2753a53663b9b8e6dfc1a.59948e1fef260da10a0cecb8b6862373c32f40001848a63f985ab4f9d787f3f1\n",
            "Model config RagConfig {\n",
            "  \"_name_or_path\": \"facebook/rag-token-nq\",\n",
            "  \"architectures\": [\n",
            "    \"RagTokenForGeneration\"\n",
            "  ],\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      0,\n",
            "      0\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"dataset\": \"wiki_dpr\",\n",
            "  \"dataset_split\": \"train\",\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"do_deduplication\": true,\n",
            "  \"do_marginalize\": false,\n",
            "  \"doc_sep\": \" // \",\n",
            "  \"eos_token_id\": 2,\n",
            "  \"exclude_bos_score\": false,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"generator\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"_num_labels\": 3,\n",
            "    \"activation_dropout\": 0.0,\n",
            "    \"activation_function\": \"gelu\",\n",
            "    \"add_bias_logits\": false,\n",
            "    \"add_cross_attention\": false,\n",
            "    \"add_final_layer_norm\": false,\n",
            "    \"architectures\": [\n",
            "      \"BartForConditionalGeneration\"\n",
            "    ],\n",
            "    \"attention_dropout\": 0.0,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classif_dropout\": 0.0,\n",
            "    \"classifier_dropout\": 0.0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"d_model\": 1024,\n",
            "    \"decoder_attention_heads\": 16,\n",
            "    \"decoder_ffn_dim\": 4096,\n",
            "    \"decoder_layerdrop\": 0.0,\n",
            "    \"decoder_layers\": 12,\n",
            "    \"decoder_start_token_id\": 2,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"dropout\": 0.1,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_attention_heads\": 16,\n",
            "    \"encoder_ffn_dim\": 4096,\n",
            "    \"encoder_layerdrop\": 0.0,\n",
            "    \"encoder_layers\": 12,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"extra_pos_embeddings\": 2,\n",
            "    \"finetuning_task\": null,\n",
            "    \"force_bos_token_to_be_generated\": true,\n",
            "    \"forced_bos_token_id\": 0,\n",
            "    \"forced_eos_token_id\": 2,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\",\n",
            "      \"2\": \"LABEL_2\"\n",
            "    },\n",
            "    \"init_std\": 0.02,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": true,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1,\n",
            "      \"LABEL_2\": 2\n",
            "    },\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 1024,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bart\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"normalize_before\": false,\n",
            "    \"normalize_embedding\": true,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_past\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"scale_embedding\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"static_position_embeddings\": false,\n",
            "    \"task_specific_params\": {\n",
            "      \"summarization\": {\n",
            "        \"early_stopping\": true,\n",
            "        \"length_penalty\": 2.0,\n",
            "        \"max_length\": 142,\n",
            "        \"min_length\": 56,\n",
            "        \"no_repeat_ngram_size\": 3,\n",
            "        \"num_beams\": 4\n",
            "      }\n",
            "    },\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"index_name\": \"legacy\",\n",
            "  \"index_path\": null,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label_smoothing\": 0.0,\n",
            "  \"max_combined_length\": 300,\n",
            "  \"max_length\": 50,\n",
            "  \"min_length\": 1,\n",
            "  \"model_type\": \"rag\",\n",
            "  \"n_docs\": 5,\n",
            "  \"num_beams\": 4,\n",
            "  \"output_retrieved\": false,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"passages_path\": null,\n",
            "  \"question_encoder\": {\n",
            "    \"_name_or_path\": \"\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"DPRQuestionEncoder\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"dpr\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"projection_dim\": 0,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": false,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 30522\n",
            "  },\n",
            "  \"reduce_loss\": false,\n",
            "  \"retrieval_batch_size\": 8,\n",
            "  \"retrieval_vector_size\": 768,\n",
            "  \"title_sep\": \" / \",\n",
            "  \"transformers_version\": null,\n",
            "  \"use_cache\": true,\n",
            "  \"use_dummy_dataset\": false,\n",
            "  \"vocab_size\": null\n",
            "}\n",
            "\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
            "The class this function is called from is 'BartTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1. Try a Question"
      ],
      "metadata": {
        "id": "SFfJsdu-HVqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "question = \"Who is Arya's father?\"\n",
        "\n",
        "# Tokenize the question.\n",
        "input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# Give the question to RAG and have it generate an answer!\n",
        "generated = model.generate(input_ids)\n",
        "\n",
        "# Convert the answer tokens back into a single string.\n",
        "generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "\n",
        "print (\"Q: \" + question)\n",
        "print (\"A: \" + generated_string)\n",
        "\n",
        "print('\\nResponse took %.2f seconds' % (time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbfb15d5-ade7-4869-dc2f-c9ececf594c9",
        "id": "-64vtwywHYpj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1590: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=max_length)])` instead.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Who is Arya's father?\n",
            "A:  lord eddard stark\n",
            "\n",
            "Response took 8.94 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. Wrap with \"GenerativeQAModule\""
      ],
      "metadata": {
        "id": "f-8ORrpdRf-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the model object. This will do all of the downloading of the model parameters and dataset!"
      ],
      "metadata": {
        "id": "k3CS9OjYWKc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model: GenerativeQAModule = GenerativeQAModule(args, config, tokenizer, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sP449et9sxl",
        "outputId": "8a5e330d-a024-4c24-c432-f7aba415de47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/parsing.py:245: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
            "  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S4. Fine-Tuning"
      ],
      "metadata": {
        "id": "oT55BjdZEgqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Responses before tuning"
      ],
      "metadata": {
        "id": "Vi0ZLFwHrSMl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0boLFK7Z6rPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "questions = [\n",
        "    \"Tommen’s cat was named _____.\", # Ser Pounce\n",
        "    \"What was the name of Tommen's cat?\",\n",
        "    \n",
        "    \"Tyrion sent Janos Slynt to _____.\", # The Night's Watch\n",
        "    \"Where did Tyrion send Janos Slynt?\",\n",
        "\n",
        "    \"_____ is the name of Stannis’ sword.\", # Lightbringer\n",
        "    \"What is the name of Stannis' sword?\",\n",
        "\n",
        "    \"_____ saved Sansa from the mob in King’s Landing?\", # The Hound\n",
        "    \"Who saved Sansa from the mob in King's Landing?\",\n",
        "\n",
        "    \"Mother of Robb Stark.\", # Catelyn Stark\n",
        "    \"Who is Robb Stark's mother?\",\n",
        "\n",
        "    \"The House of Black and White is a temple located in _____ dedicated to the Many-Faced God.\", # Bravos. (incorrect spelling. Should be \"Braavos\")\n",
        "    \"The House of Black and White is a temple dedicated to the Many-Faced God in which city?\",\n",
        "\n",
        "    \"King asked Ned to take the title _____.\", # Hand of the King.\n",
        "    \"What title was Ned asked to take by the King?\"\n",
        "\n",
        "    \"Who is Arya's father?\",\n",
        "    \"Where is Theon Greyjoy from?\",\n",
        "    \"What is the title of the first episode?\",\n",
        "    \"Who succeeded Robert Baratheon on the Iron Throne?\",\n",
        "    \"At the beginning of the series, how many children do Ned and Catelyn Stark have?\",\n",
        "    \"Who is the first character in the series to be called 'King in the North'?\",\n",
        "    \"Which cast member did Kit Harington marry in 2018?\",\n",
        "    \"How does Daenerys hatch her dragon eggs?\",\n",
        "    \"What is the name of Arya's direwolf?\",\n",
        "    \"Which house has a rose as its sigil?\",\n",
        "\n",
        "    \"Who is Robb Stark's mom?\",\n",
        "    \"Who does Robb Stark call his mother?\",\n",
        "    \"What weapon does Stannis carry around?\",\n",
        "    \"Is Stannis' sword named Widow's Wail?\",\n",
        "    \"______ is the name of Tommen's cat, but not the name of Arya's sword.\",\n",
        "    \"Why does Hodor say 'Hodor'?\"\n",
        "\n",
        "    \"After capturing Mareena, why doesn't Daenerys continue on to conquer King's Landing?\",\n",
        "    \"What is the name of Tommen's cat, but not the name of Arya's sword?\",\n",
        "    \"Does Arya own a sword named 'Needle'?\",\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "prev_answers = []\n",
        "\n",
        "for question in questions:\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Tokenize the question.\n",
        "    input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "    # Give the question to RAG and have it generate an answer!\n",
        "    generated = model.model.generate(input_ids)\n",
        "\n",
        "    # Convert the answer tokens back into a single string.\n",
        "    generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "\n",
        "    print (\"\\nQ: \" + question)\n",
        "    print (\"A: \" + generated_string)\n",
        "\n",
        "    prev_answers.append(generated_string)\n",
        "\n",
        "    #print('\\nResponse took %.2f seconds' % (time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272067e5-5a62-4593-aa92-6baf46d39c7f",
        "id": "XjDiYEX-6rbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1590: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=max_length)])` instead.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: After capturing Mareena, why doesn't Daenerys continue on to conquer King's Landing?\n",
            "A:  to avoid bloodshed\n",
            "\n",
            "Q: What is the name of Tommen's cat, but not the name of Arya's sword?\n",
            "A:  needle\n",
            "\n",
            "Q: Does Arya own a sword named 'Needle'?\n",
            "A:  given to her by jon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tokenizer))\n",
        "print(type(tokenizer.generator))\n",
        "print(type(tokenizer.question_encoder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oGwY5zRBWFc",
        "outputId": "08e53e78-3778-420b-f936-4cde87f53f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.rag.tokenization_rag.RagTokenizer'>\n",
            "<class 'transformers.models.bart.tokenization_bart_fast.BartTokenizerFast'>\n",
            "<class 'transformers.models.dpr.tokenization_dpr_fast.DPRQuestionEncoderTokenizerFast'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Logging and Callbacks"
      ],
      "metadata": {
        "id": "01HZIjoQWoHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Path(args.data_dir).name"
      ],
      "metadata": {
        "id": "OKJb4boTWJQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QGGQNY9zeFix",
        "outputId": "a36f11f7-7fac-417c-f6ed-231c6705d3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up logging..."
      ],
      "metadata": {
        "id": "KVmOiABIWraa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.logger_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WMm61XzIeQdc",
        "outputId": "38b2f45c-edf4-41e6-c1af-54da8f343242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'default'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if (\n",
        "    args.logger_name == \"default\"\n",
        "    or args.fast_dev_run\n",
        "    or str(args.output_dir).startswith(\"/tmp\")\n",
        "    or str(args.output_dir).startswith(\"/var\")\n",
        "):\n",
        "    training_logger = True  # don't pollute wandb logs unnecessarily\n",
        "\n",
        "elif args.logger_name == \"wandb\":\n",
        "    from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "    project = os.environ.get(\"WANDB_PROJECT\", dataset)\n",
        "    training_logger = WandbLogger(name=model.output_dir.name, project=project)\n",
        "\n",
        "\n",
        "elif args.logger_name == \"wandb_shared\":\n",
        "    from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "    training_logger = WandbLogger(name=model.output_dir.name, project=f\"hf_{dataset}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "38j0OTloWjrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stopping callback."
      ],
      "metadata": {
        "id": "UVRtSQcMWyYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "es_callback = (\n",
        "    get_early_stopping_callback(model.val_metric, args.early_stopping_patience)\n",
        "    if args.early_stopping_patience >= 0\n",
        "    else False\n",
        ")\n"
      ],
      "metadata": {
        "id": "MgCpjRSJWxsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a PyTorch Lightning trainer object."
      ],
      "metadata": {
        "id": "bSJP_0KNW389"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.profile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vmw-QjzeaIi",
        "outputId": "5ef6a757-19d1-4ec2-8e05-621f262a3a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logger = logging.getLogger('my_logger')\n",
        "\n",
        "# Logging levels:\n",
        "#   DEBUG\n",
        "#   INFO\n",
        "#   WARNING\n",
        "#   ERROR\n",
        "#   CRITICAL\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO \n",
        "    )"
      ],
      "metadata": {
        "id": "dj9DBCRafTSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Tweak Arguments"
      ],
      "metadata": {
        "id": "IeF5IZSVf5hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__file__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gu2X8ivGpiKo",
        "outputId": "72d426c1-c14e-4a69-9bd7-f2097c227e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.7/dist-packages/transformers/__init__.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd /usr/local/lib/python3.7/dist-packages/transformers/models/rag/\n",
        "\n",
        "# retrieval_rag.py"
      ],
      "metadata": {
        "id": "J8fFewI-oLTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(args.train_batch_size)\n",
        "\n",
        "#args.enable_checkpointing = False\n",
        "#model.hparams.enable_checkpointing = False\n",
        "\n",
        "if False:\n",
        "    args.train_batch_size = 8\n",
        "    model.hparams.train_batch_size = 8\n",
        "    args.accumulate_grad_batches = 1\n",
        "    model.hparams.accumulate_grad_batches = 1\n",
        "    model.hparams.max_epochs = 100"
      ],
      "metadata": {
        "id": "27R9awWfgjBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.hparams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nw1FLmWh3a7",
        "outputId": "194aa7c7-e2d8-4d0c-ae5b-4419b09808f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"accelerator\":                       None\n",
              "\"accumulate_grad_batches\":           1\n",
              "\"actor_handles\":                     []\n",
              "\"adafactor\":                         False\n",
              "\"adam_epsilon\":                      1e-08\n",
              "\"amp_backend\":                       native\n",
              "\"amp_level\":                         None\n",
              "\"attention_dropout\":                 None\n",
              "\"auto_lr_find\":                      False\n",
              "\"auto_scale_batch_size\":             False\n",
              "\"auto_select_gpus\":                  False\n",
              "\"benchmark\":                         None\n",
              "\"cache_dir\":                         \n",
              "\"check_val_every_n_epoch\":           1\n",
              "\"checkpoint_callback\":               False\n",
              "\"config_name\":                       \n",
              "\"data_dir\":                          ./data\n",
              "\"decoder_layerdrop\":                 None\n",
              "\"default_root_dir\":                  None\n",
              "\"detect_anomaly\":                    False\n",
              "\"deterministic\":                     False\n",
              "\"devices\":                           None\n",
              "\"distributed_port\":                  -1\n",
              "\"distributed_retriever\":             pytorch\n",
              "\"do_predict\":                        False\n",
              "\"do_train\":                          False\n",
              "\"dropout\":                           None\n",
              "\"early_stopping_patience\":           -1\n",
              "\"enable_checkpointing\":              False\n",
              "\"enable_model_summary\":              True\n",
              "\"enable_progress_bar\":               True\n",
              "\"encoder_layerdrop\":                 None\n",
              "\"eval_batch_size\":                   32\n",
              "\"fast_dev_run\":                      False\n",
              "\"flush_logs_every_n_steps\":          None\n",
              "\"fp16\":                              True\n",
              "\"fp16_opt_level\":                    O2\n",
              "\"gpus\":                              1\n",
              "\"gradient_clip_algorithm\":           None\n",
              "\"gradient_clip_val\":                 None\n",
              "\"index_name\":                        None\n",
              "\"index_path\":                        None\n",
              "\"ipus\":                              None\n",
              "\"label_smoothing\":                   0.0\n",
              "\"learning_rate\":                     5e-05\n",
              "\"limit_predict_batches\":             None\n",
              "\"limit_test_batches\":                None\n",
              "\"limit_train_batches\":               None\n",
              "\"limit_val_batches\":                 None\n",
              "\"log_every_n_steps\":                 50\n",
              "\"log_gpu_memory\":                    None\n",
              "\"logger\":                            True\n",
              "\"logger_name\":                       default\n",
              "\"lr_scheduler\":                      linear\n",
              "\"max_epochs\":                        3\n",
              "\"max_source_length\":                 128\n",
              "\"max_steps\":                         -1\n",
              "\"max_target_length\":                 25\n",
              "\"max_time\":                          None\n",
              "\"min_epochs\":                        None\n",
              "\"min_steps\":                         None\n",
              "\"model_name_or_path\":                facebook/rag-token-base\n",
              "\"model_type\":                        rag_token\n",
              "\"move_metrics_to_cpu\":               False\n",
              "\"multiple_trainloader_mode\":         max_size_cycle\n",
              "\"n_test\":                            -1\n",
              "\"n_train\":                           -1\n",
              "\"n_val\":                             -1\n",
              "\"num_nodes\":                         1\n",
              "\"num_processes\":                     None\n",
              "\"num_sanity_val_steps\":              2\n",
              "\"num_workers\":                       4\n",
              "\"output_dir\":                        ./output\n",
              "\"overfit_batches\":                   0.0\n",
              "\"passages_path\":                     None\n",
              "\"plugins\":                           None\n",
              "\"precision\":                         32\n",
              "\"prefix\":                            None\n",
              "\"prepare_data_per_node\":             None\n",
              "\"process_position\":                  0\n",
              "\"profile\":                           False\n",
              "\"profiler\":                          None\n",
              "\"progress_bar_refresh_rate\":         None\n",
              "\"reload_dataloaders_every_n_epochs\": 0\n",
              "\"replace_sampler_ddp\":               True\n",
              "\"resume_from_checkpoint\":            None\n",
              "\"seed\":                              42\n",
              "\"stochastic_weight_avg\":             False\n",
              "\"strategy\":                          None\n",
              "\"sync_batchnorm\":                    False\n",
              "\"terminate_on_nan\":                  None\n",
              "\"test_max_target_length\":            25\n",
              "\"tokenizer_name\":                    None\n",
              "\"tpu_cores\":                         None\n",
              "\"track_grad_norm\":                   -1\n",
              "\"train_batch_size\":                  1\n",
              "\"use_dummy_dataset\":                 True\n",
              "\"val_check_interval\":                None\n",
              "\"val_max_target_length\":             25\n",
              "\"warmup_steps\":                      0\n",
              "\"weight_decay\":                      0.0\n",
              "\"weights_save_path\":                 None\n",
              "\"weights_summary\":                   top"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.do_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZXnwFOHf8gy",
        "outputId": "37d995e1-ed77-4bc4-bad1-304c11f161fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. Create Trainer Object"
      ],
      "metadata": {
        "id": "zR4wKj2ZpqjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6vaoJORn-LmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This `generic_train` function comes from the transformers library [here](https://github.com/huggingface/transformers/blob/main/examples/legacy/pytorch-lightning/lightning_base.py)"
      ],
      "metadata": {
        "id": "qXrK0SEDgJua"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O2Lszl_5l4QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's just create the trainer in this step.\n",
        "args.do_train = False\n",
        "\n",
        "# Create a Trainer object.\n",
        "trainer: pl.Trainer = generic_train(\n",
        "    model,\n",
        "    \n",
        "    args,\n",
        "    \n",
        "    logging_callback = Seq2SeqLoggingCallback(),\n",
        "    \n",
        "    checkpoint_callback = get_checkpoint_callback(args.output_dir, model.val_metric),\n",
        "    \n",
        "    early_stopping_callback = es_callback,\n",
        "    \n",
        "    logger = training_logger,\n",
        "    \n",
        "    #custom_ddp_plugin=CustomDDP() if args.gpus > 1 else None,\n",
        "    custom_ddp_plugin = None,\n",
        "    \n",
        "    profiler=pl.profiler.AdvancedProfiler() if args.profile else None,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_9oxrhbV_9k",
        "outputId": "a5142ceb-19ab-4076-e110-fcf445d5cd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:440: UserWarning: The flag `devices=auto` will be ignored, instead the device specific number 1 will be used\n",
            "  f\"The flag `devices={devices}` will be ignored, \"\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
            "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:172: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
            "  \"Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5. Run Training!"
      ],
      "metadata": {
        "id": "ZZlV1gUzpvHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's do the training!"
      ],
      "metadata": {
        "id": "3h_Zow9ogTc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sbk80yVigiKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "7d3bde393442470ba508a7f387cd0e18",
            "0203690799334f63a115338b03fc79ea",
            "13f958e13e95406bba1ddd97d1d75973",
            "51b2bca1dedc4cfdabd5f8199cff2131",
            "aa09accaee5e414d95c35166dfc030b0",
            "fe1f384b7ec8464e84094b7f2d245e59",
            "9e358e3b464f4fb2bfab6148869306ab",
            "ec90295e1c98412788c4d23e2fdba8ac",
            "3b40a7b037554e32b5b21fadcada56b3",
            "6d6b19156c80438bb3d9587c2a3394da",
            "b2a8da355b314c8593719a09ed01f966",
            "ca50d9af846d451a8b89b31eee7c2e80",
            "9b3ca0ddb5564585957390303d41d249",
            "d0ef7e3f7d024a8e9d862e6f2a6a2f1d",
            "9e697086be6b4d83ba7feacd3df19840",
            "274e0e4435b341288931aeb459213013",
            "29726764860843f4b2a0b709ff32f02f",
            "8a43b378c190452fb68257bc486243f7",
            "022c6a5d2e3f48409eb97de024e7deb0",
            "4334055a3bad4d988bd696f6d17f3b0d",
            "e2748da67ad84404a3e0d640385d5f93",
            "fc13d66d83284e408e564ee5793d1647",
            "66a709d1f8ed4215a6b5a836056befce",
            "11d06b3782e74f91985857af13230473",
            "05fa5929b11048818e5e04e83ec6a3e7",
            "bcc0ddf449a44b1ab1cbe75bd0792dd9",
            "13d57c0d2ca14b63b241bf3fe0ebc6ac",
            "f3a1e4f5bb1e4f26980db6b9a14b4c7b",
            "90d74685e00d4516a63975743f2001ba",
            "b99a4c2dfc424324ba70a486ac607a98",
            "4ef0a923b91747ac9fc34147d290e313",
            "7821a17c18f04ebface06d1e7ace1e9a",
            "bb3d0b28960c41a28dbbc9502ef86b78",
            "45496669456146788089b4a2232f830d",
            "1a9650142ecd4baeb0f0c36a2adf1e2c",
            "72a3ac70e90542e49246d10303d801cf",
            "e0d979d9e8974983a76f81778b9d0be4",
            "d76ad57794164052a9f0d5658290abfa",
            "dbbe813976a14103b6b8289868a255e1",
            "85cd550207ce4eeeaba5e760080be63e",
            "b50dbec4f75a496da6b985c406eebe46",
            "2a4a2eeca5b04096a3c9e9d647cb0523",
            "dee484876697453d8fa81d8721feeacd",
            "6e476c7fa64d4b31a7feac5901aac068",
            "01b6498a155c4bfaa30d46c2ada6053f",
            "28495c5c3eb04403945e49400f108026",
            "5eefb6ca19f64014b46f96de4580617b",
            "9bec16aa526242a9b040f5eb404bd44e",
            "9a957967d428458d9c4b291f47754ade",
            "4feb01b423724a0c9eb7e08296068f45",
            "70f5b41292234c339821b05f9844dc15",
            "40306e9d78634882a929d4363c0cd357",
            "8eaf2b37fbf242178e430454f9b7fd9d",
            "6adad24c069f4e73887323e5eaddb7e6",
            "4c50fbfd64f24b2a9c28f15377499b8f"
          ]
        },
        "id": "eyCjNzvYgVGp",
        "outputId": "f0e9850f-7c2a-429c-93e7-601ae5b52ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
            "  f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "initializing retrieval\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d3bde393442470ba508a7f387cd0e18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1590: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=max_length)])` instead.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca50d9af846d451a8b89b31eee7c2e80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66a709d1f8ed4215a6b5a836056befce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45496669456146788089b4a2232f830d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01b6498a155c4bfaa30d46c2ada6053f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# S5. Testing and Evaluation"
      ],
      "metadata": {
        "id": "9nJgTWJEt4RM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. trainer.test"
      ],
      "metadata": {
        "id": "UGO7MvqO21sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: there is an argument, \"args.do_predict:\" intended to govern this.\n",
        "# Note: test() without a model tests using the best checkpoint automatically\n",
        "trainer.test(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "976b2eac1d4b43aa97384aa926bb5aa8",
            "a553bc1b204b4e07a70c6e241d4a9a73",
            "891e963f1c9941e097cbf93ed3010ab4",
            "3c81fb48d3914d22aa3613c0f4f4462e",
            "4ba75d35d10f477fb7cb956b0717119a",
            "5e20746414b24e1a82e3f2a2fa62f5ad",
            "aa7e663d6582481fb3f820e4b9fb9f7d",
            "a57594f7c09e474291a0a9b2773bc38a",
            "92092c50d9274473814347c4b42f28b5",
            "cfa5b7d130184bc8915e02a882d196be",
            "5143fc1190a244188157b667533d8fed"
          ]
        },
        "id": "kVHfB_lht6F2",
        "outputId": "967486d2-1943-470b-8be1-392e0aca3a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
            "  f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "976b2eac1d4b43aa97384aa926bb5aa8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1590: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=max_length)])` instead.\n",
            "  UserWarning,\n",
            "INFO:my_logger:***** test results at step 00342 *****\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5.2. Ask Questions"
      ],
      "metadata": {
        "id": "C-fSncsmDcNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "question = \"Who is Arya's father?\"\n",
        "\n",
        "# Tokenize the question.\n",
        "input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# Give the question to RAG and have it generate an answer!\n",
        "generated = model.model.generate(input_ids)\n",
        "\n",
        "# Convert the answer tokens back into a single string.\n",
        "generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "\n",
        "print (\"Q: \" + question)\n",
        "print (\"A: \" + generated_string)\n",
        "\n",
        "print('\\nResponse took %.2f seconds' % (time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FASCt80DfKT",
        "outputId": "78caabce-0cc3-48da-fae1-4f92b2bd990d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1590: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=max_length)])` instead.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: Who is Arya's father?\n",
            "A: Lord Edwin Lannister.\n",
            "\n",
            "Response took 10.23 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTHGussbPg6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "question = \"Who is Arya's father?\"\n",
        "\n",
        "# Tokenize the question.\n",
        "input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# Give the question to RAG and have it generate an answer!\n",
        "# \n",
        "generated = model.model.generate(input_ids, num_beams=4, max_length=5)\n",
        "\n",
        "# Convert the answer tokens back into a single string.\n",
        "generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "\n",
        "print (\"Q: \" + question)\n",
        "print (\"A: \" + generated_string)\n",
        "\n",
        "print('\\nResponse took %.2f seconds' % (time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecaf5be7-f99f-446d-eda8-0042ef532e49",
        "id": "J0oLuUWOPi2O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:2097: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList(MaxLengthCriteria(max_length=max_length))` instead.\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9kSEXSLKqTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "new_answers = []\n",
        "\n",
        "for question in questions:\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Tokenize the question.\n",
        "    input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "    # Give the question to RAG and have it generate an answer!\n",
        "    generated = model.model.generate(input_ids)\n",
        "\n",
        "    # Convert the answer tokens back into a single string.\n",
        "    generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "\n",
        "    print (\"\\nQ: \" + question)\n",
        "    print (\"A: \" + generated_string)\n",
        "\n",
        "    new_answers.append(generated_string)\n",
        "\n",
        "    #print('\\nResponse took %.2f seconds' % (time.time() - t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ca5651-e63d-458d-e5e4-ff64ec78dc63",
        "id": "XhU-La31Kqdu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1590: UserWarning: `max_length` is deprecated in this function, use `stopping_criteria=StoppingCriteriaList([MaxLengthCriteria(max_length=max_length)])` instead.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: Tommen’s cat was named _____.\n",
            "A: Brynden.\n",
            "\n",
            "Q: What was the name of Tommen's cat?\n",
            "A: Ser Pounce.\n",
            "\n",
            "Q: Tyrion sent Janos Slynt to _____.\n",
            "A: The Night’s Watch.\n",
            "\n",
            "Q: Where did Tyrion send Janos Slynt?\n",
            "A: The Great Pyramid\n",
            "\n",
            "Q: _____ is the name of Stannis’ sword.\n",
            "A: Widow’s Wail.\n",
            "\n",
            "Q: What is the name of Stannis' sword?\n",
            "A: The Great Sealord.\n",
            "\n",
            "Q: _____ saved Sansa from the mob in King’s Landing?\n",
            "A: Brienne of Tarth.\n",
            "\n",
            "Q: Who saved Sansa from the mob in King's Landing?\n",
            "A: Brienne.\n",
            "\n",
            "Q: Mother of Robb Stark.\n",
            "A: Catelyn Stark.\n",
            "\n",
            "Q: Who is Robb Stark's mother?\n",
            "A: Catelyn Stark.\n",
            "\n",
            "Q: The House of Black and White is a temple located in _____ dedicated to the Many-Faced God.\n",
            "A: Bravos.\n",
            "\n",
            "Q: The House of Black and White is a temple dedicated to the Many-Faced God in which city?\n",
            "A: Belfast\n",
            "\n",
            "Q: King asked Ned to take the title _____.\n",
            "A: The King’s Hand.\n",
            "\n",
            "Q: What title was Ned asked to take by the King?Who is Arya's father?\n",
            "A: Hand of the King.\n",
            "\n",
            "Q: Where is Theon Greyjoy from?\n",
            "A: The Night’s Watch.\n",
            "\n",
            "Q: What is the title of the first episode?\n",
            "A: The Night’s Watch.\n",
            "\n",
            "Q: Who succeeded Robert Baratheon on the Iron Throne?\n",
            "A: Jorah Mormont.\n",
            "\n",
            "Q: At the beginning of the series, how many children do Ned and Catelyn Stark have?\n",
            "A: Three.\n",
            "\n",
            "Q: Who is the first character in the series to be called 'King in the North'?\n",
            "A: Robb Stark.\n",
            "\n",
            "Q: Which cast member did Kit Harington marry in 2018?\n",
            "A: Melisandre.\n",
            "\n",
            "Q: How does Daenerys hatch her dragon eggs?\n",
            "A: Hatching.\n",
            "\n",
            "Q: What is the name of Arya's direwolf?\n",
            "A: Nymeria.\n",
            "\n",
            "Q: Which house has a rose as its sigil?\n",
            "A: House Greyjoy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(questions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBr41bqhDJ2R",
        "outputId": "ccbd8d0d-1b0a-4f8d-e86f-bfca9d110752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tommen’s cat was named _____.', \"What was the name of Tommen's cat?\", 'Tyrion sent Janos Slynt to _____.', 'Where did Tyrion send Janos Slynt?', '_____ is the name of Stannis’ sword.', \"What is the name of Stannis' sword?\", '_____ saved Sansa from the mob in King’s Landing?', \"Who saved Sansa from the mob in King's Landing?\", 'Mother of Robb Stark.', \"Who is Robb Stark's mother?\", 'The House of Black and White is a temple located in _____ dedicated to the Many-Faced God.', 'The House of Black and White is a temple dedicated to the Many-Faced God in which city?', 'King asked Ned to take the title _____.', \"What title was Ned asked to take by the King?Who is Arya's father?\", 'Where is Theon Greyjoy from?', 'What is the title of the first episode?', 'Who succeeded Robert Baratheon on the Iron Throne?', 'At the beginning of the series, how many children do Ned and Catelyn Stark have?', \"Who is the first character in the series to be called 'King in the North'?\", 'Which cast member did Kit Harington marry in 2018?', 'How does Daenerys hatch her dragon eggs?', \"What is the name of Arya's direwolf?\", 'Which house has a rose as its sigil?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prev_answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUqBfCA1DMdr",
        "outputId": "01e8a68a-45f9-4e44-93e6-926d9533f7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ser pounce', ' ser pounce', ' mance', ' mance', ' hearts', ' the', ' tyrion', ' theon', ' catelyn stark', ' lady catelyn', ' braavos', ' braavos', ' the', ' hand of the king', ' the iron islands', ' winter is coming', '', ' five', ' robin', ' rose leslie', ' ancient fossilized dragon eggs', ' nymer', ' house of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFjxPIKkDNvR",
        "outputId": "86c964c0-4d89-460c-af88-13ea64033457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Brynden.', 'Ser Pounce.', 'The Night’s Watch.', 'The Great Pyramid', 'Widow’s Wail.', 'The Great Sealord.', 'Brienne of Tarth.', 'Brienne.', 'Catelyn Stark.', 'Catelyn Stark.', 'Bravos.', 'Belfast', 'The King’s Hand.', 'Hand of the King.', 'The Night’s Watch.', 'The Night’s Watch.', 'Jorah Mormont.', 'Three.', 'Robb Stark.', 'Melisandre.', 'Hatching.', 'Nymeria.', 'House Greyjoy.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for q in new_answers:\n",
        "    print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH-JGhyrGqje",
        "outputId": "b6339bd4-1989-404a-8b86-edfb22248580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brynden.\n",
            "Ser Pounce.\n",
            "The Night’s Watch.\n",
            "The Great Pyramid\n",
            "Widow’s Wail.\n",
            "The Great Sealord.\n",
            "Brienne of Tarth.\n",
            "Brienne.\n",
            "Catelyn Stark.\n",
            "Catelyn Stark.\n",
            "Bravos.\n",
            "Belfast\n",
            "The King’s Hand.\n",
            "Hand of the King.\n",
            "The Night’s Watch.\n",
            "The Night’s Watch.\n",
            "Jorah Mormont.\n",
            "Three.\n",
            "Robb Stark.\n",
            "Melisandre.\n",
            "Hatching.\n",
            "Nymeria.\n",
            "House Greyjoy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(model.tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6kVXFsVy23m",
        "outputId": "c0cc1159-7473-4ca1-815c-7126af20b028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.rag.tokenization_rag.RagTokenizer"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(model.tokenizer.generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF1k3pQ4zMgp",
        "outputId": "1eb831a8-3f43-47ac-fb3d-7fc145849766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.bart.tokenization_bart_fast.BartTokenizerFast"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix"
      ],
      "metadata": {
        "id": "87HIxAXl29ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A1. Save"
      ],
      "metadata": {
        "id": "qpP-wtu4elfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "fkypAq0FuKuQ",
        "outputId": "28be99ac-0b6b-41f6-9480-ee81d6bf8bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-fd5dede08c85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GenerativeQAModule' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pickle_save(model.hparams, model.output_dir / \"hparams.pkl\")\n"
      ],
      "metadata": {
        "id": "Z1nE9xyjW7uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2. Answers before fine-tuning"
      ],
      "metadata": {
        "id": "S6101DUjDbWN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bujnt5s9DdQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "questions = [\n",
        "    \"Mother of Robb Stark.\", # Catelyn Stark\n",
        "    \"Who is Robb Stark's mother?\",\n",
        "\n",
        "    \"The House of Black and White is a temple located in _____ dedicated to the Many-Faced God.\", # Bravos. (incorrect spelling. Should be \"Braavos\")\n",
        "    \"The House of Black and White is a temple dedicated to the Many-Faced God in which city?\",\n",
        "\n",
        "    \"King asked Ned to take the title _____.\", # Hand of the King.\n",
        "    \"What title was Ned asked to take by the King?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Tokenize the question.\n",
        "    input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "    # Give the question to RAG and have it generate an answer!\n",
        "    generated = model.model.generate(input_ids)\n",
        "\n",
        "    # Convert the answer tokens back into a single string.\n",
        "    generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "\n",
        "    print (\"\\nQ: \" + question)\n",
        "    print (\"A: \" + generated_string)\n",
        "\n",
        "    #print('\\nResponse took %.2f seconds' % (time.time() - t0))"
      ],
      "metadata": {
        "id": "sggOfDCT-0_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "questions = [\n",
        "    \"Who is Arya's father?\",\n",
        "    \"Where is Theon Greyjoy from?\",\n",
        "    \"What is the title of the first episode?\",\n",
        "    \"Who succeeded Robert Baratheon on the Iron Throne?\",\n",
        "    \"At the beginning of the series, how many children do Ned and Catelyn Stark have?\",\n",
        "    \"Who is the first character in the series to be called 'King in the North'?\",\n",
        "    \"Which cast member did Kit Harington marry in 2018?\",\n",
        "    \"How does Daenerys hatch her dragon eggs?\",\n",
        "    \"What is the name of Arya's direwolf?\",\n",
        "    \"Which house has a rose as its sigil?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Tokenize the question.\n",
        "    input_ids = tokenizer.question_encoder(question, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "    # Give the question to RAG and have it generate an answer!\n",
        "    generated = model.model.generate(input_ids)\n",
        "\n",
        "    # Convert the answer tokens back into a single string.\n",
        "    generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
        "\n",
        "    print (\"\\nQ: \" + question)\n",
        "    print (\"A: \" + generated_string)\n",
        "\n",
        "    #print('\\nResponse took %.2f seconds' % (time.time() - t0))"
      ],
      "metadata": {
        "id": "qw2e9NDDIy5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A2. Script Arguments"
      ],
      "metadata": {
        "id": "nibg4a3vVnmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "usage: finetune_rag.py [-h] [--logger [LOGGER]]\n",
        "                       [--checkpoint_callback [CHECKPOINT_CALLBACK]]\n",
        "                       [--enable_checkpointing [ENABLE_CHECKPOINTING]]\n",
        "                       [--default_root_dir DEFAULT_ROOT_DIR]\n",
        "                       [--gradient_clip_val GRADIENT_CLIP_VAL]\n",
        "                       [--gradient_clip_algorithm GRADIENT_CLIP_ALGORITHM]\n",
        "                       [--process_position PROCESS_POSITION]\n",
        "                       [--num_nodes NUM_NODES] [--num_processes NUM_PROCESSES]\n",
        "                       [--devices DEVICES] [--gpus GPUS]\n",
        "                       [--auto_select_gpus [AUTO_SELECT_GPUS]]\n",
        "                       [--tpu_cores TPU_CORES] [--ipus IPUS]\n",
        "                       [--log_gpu_memory LOG_GPU_MEMORY]\n",
        "                       [--progress_bar_refresh_rate PROGRESS_BAR_REFRESH_RATE]\n",
        "                       [--enable_progress_bar [ENABLE_PROGRESS_BAR]]\n",
        "                       [--overfit_batches OVERFIT_BATCHES]\n",
        "                       [--track_grad_norm TRACK_GRAD_NORM]\n",
        "                       [--check_val_every_n_epoch CHECK_VAL_EVERY_N_EPOCH]\n",
        "                       [--fast_dev_run [FAST_DEV_RUN]]\n",
        "                       [--accumulate_grad_batches ACCUMULATE_GRAD_BATCHES]\n",
        "                       [--max_epochs MAX_EPOCHS] [--min_epochs MIN_EPOCHS]\n",
        "                       [--max_steps MAX_STEPS] [--min_steps MIN_STEPS]\n",
        "                       [--max_time MAX_TIME]\n",
        "                       [--limit_train_batches LIMIT_TRAIN_BATCHES]\n",
        "                       [--limit_val_batches LIMIT_VAL_BATCHES]\n",
        "                       [--limit_test_batches LIMIT_TEST_BATCHES]\n",
        "                       [--limit_predict_batches LIMIT_PREDICT_BATCHES]\n",
        "                       [--val_check_interval VAL_CHECK_INTERVAL]\n",
        "                       [--flush_logs_every_n_steps FLUSH_LOGS_EVERY_N_STEPS]\n",
        "                       [--log_every_n_steps LOG_EVERY_N_STEPS]\n",
        "                       [--accelerator ACCELERATOR] [--strategy STRATEGY]\n",
        "                       [--sync_batchnorm [SYNC_BATCHNORM]]\n",
        "                       [--precision PRECISION]\n",
        "                       [--enable_model_summary [ENABLE_MODEL_SUMMARY]]\n",
        "                       [--weights_summary WEIGHTS_SUMMARY]\n",
        "                       [--weights_save_path WEIGHTS_SAVE_PATH]\n",
        "                       [--num_sanity_val_steps NUM_SANITY_VAL_STEPS]\n",
        "                       [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
        "                       [--profiler PROFILER] [--benchmark [BENCHMARK]]\n",
        "                       [--deterministic [DETERMINISTIC]]\n",
        "                       [--reload_dataloaders_every_n_epochs RELOAD_DATALOADERS_EVERY_N_EPOCHS]\n",
        "                       [--auto_lr_find [AUTO_LR_FIND]]\n",
        "                       [--replace_sampler_ddp [REPLACE_SAMPLER_DDP]]\n",
        "                       [--detect_anomaly [DETECT_ANOMALY]]\n",
        "                       [--auto_scale_batch_size [AUTO_SCALE_BATCH_SIZE]]\n",
        "                       [--prepare_data_per_node [PREPARE_DATA_PER_NODE]]\n",
        "                       [--plugins PLUGINS] [--amp_backend AMP_BACKEND]\n",
        "                       [--amp_level AMP_LEVEL]\n",
        "                       [--move_metrics_to_cpu [MOVE_METRICS_TO_CPU]]\n",
        "                       [--multiple_trainloader_mode MULTIPLE_TRAINLOADER_MODE]\n",
        "                       [--stochastic_weight_avg [STOCHASTIC_WEIGHT_AVG]]\n",
        "                       [--terminate_on_nan [TERMINATE_ON_NAN]]\n",
        "                       --model_name_or_path MODEL_NAME_OR_PATH\n",
        "                       [--config_name CONFIG_NAME]\n",
        "                       [--tokenizer_name TOKENIZER_NAME]\n",
        "                       [--cache_dir CACHE_DIR]\n",
        "                       [--encoder_layerdrop ENCODER_LAYERDROP]\n",
        "                       [--decoder_layerdrop DECODER_LAYERDROP]\n",
        "                       [--dropout DROPOUT]\n",
        "                       [--attention_dropout ATTENTION_DROPOUT]\n",
        "                       [--learning_rate LEARNING_RATE]\n",
        "                       [--lr_scheduler {cosine, cosine_w_restarts, linear, polynomial}]\n",
        "                       [--weight_decay WEIGHT_DECAY]\n",
        "                       [--adam_epsilon ADAM_EPSILON]\n",
        "                       [--warmup_steps WARMUP_STEPS]\n",
        "                       [--num_workers NUM_WORKERS]\n",
        "                       [--num_train_epochs MAX_EPOCHS]\n",
        "                       [--train_batch_size TRAIN_BATCH_SIZE]\n",
        "                       [--eval_batch_size EVAL_BATCH_SIZE] [--adafactor]\n",
        "                       --output_dir OUTPUT_DIR [--fp16]\n",
        "                       [--fp16_opt_level FP16_OPT_LEVEL]\n",
        "                       [--n_tpu_cores TPU_CORES]\n",
        "                       [--max_grad_norm GRADIENT_CLIP_VAL] [--do_train]\n",
        "                       [--do_predict]\n",
        "                       [--gradient_accumulation_steps ACCUMULATE_GRAD_BATCHES]\n",
        "                       [--seed SEED] --data_dir DATA_DIR\n",
        "                       [--max_source_length MAX_SOURCE_LENGTH]\n",
        "                       [--max_target_length MAX_TARGET_LENGTH]\n",
        "                       [--val_max_target_length VAL_MAX_TARGET_LENGTH]\n",
        "                       [--test_max_target_length TEST_MAX_TARGET_LENGTH]\n",
        "                       [--logger_name {default,wandb,wandb_shared}]\n",
        "                       [--n_train N_TRAIN] [--n_val N_VAL] [--n_test N_TEST]\n",
        "                       [--label_smoothing LABEL_SMOOTHING] [--prefix PREFIX]\n",
        "                       [--early_stopping_patience EARLY_STOPPING_PATIENCE]\n",
        "                       [--distributed-port DISTRIBUTED_PORT]\n",
        "                       [--model_type {rag_sequence,rag_token,bart,t5}]\n",
        "                       [--index_name INDEX_NAME]\n",
        "                       [--passages_path PASSAGES_PATH]\n",
        "                       [--index_path INDEX_PATH]\n",
        "                       [--distributed_retriever {ray,pytorch}]\n",
        "                       [--use_dummy_dataset USE_DUMMY_DATASET]\n",
        "                       [--ray-address RAY_ADDRESS]\n",
        "                       [--num_retrieval_workers NUM_RETRIEVAL_WORKERS]\n",
        "                       [--profile]\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help            show this help message and exit\n",
        "  --model_name_or_path MODEL_NAME_OR_PATH\n",
        "                        Path to pretrained model or model identifier from\n",
        "                        huggingface.co/models\n",
        "  --config_name CONFIG_NAME\n",
        "                        Pretrained config name or path if not the same as\n",
        "                        model_name\n",
        "  --tokenizer_name TOKENIZER_NAME\n",
        "                        Pretrained tokenizer name or path if not the same as\n",
        "                        model_name\n",
        "  --cache_dir CACHE_DIR\n",
        "                        Where do you want to store the pre-trained models\n",
        "                        downloaded from huggingface.co\n",
        "  --encoder_layerdrop ENCODER_LAYERDROP\n",
        "                        Encoder layer dropout probability (Optional). Goes\n",
        "                        into model.config\n",
        "  --decoder_layerdrop DECODER_LAYERDROP\n",
        "                        Decoder layer dropout probability (Optional). Goes\n",
        "                        into model.config\n",
        "  --dropout DROPOUT     Dropout probability (Optional). Goes into model.config\n",
        "  --attention_dropout ATTENTION_DROPOUT\n",
        "                        Attention dropout probability (Optional). Goes into\n",
        "                        model.config\n",
        "  --learning_rate LEARNING_RATE\n",
        "                        The initial learning rate for Adam.\n",
        "  --lr_scheduler {cosine, cosine_w_restarts, linear, polynomial}\n",
        "                        Learning rate scheduler\n",
        "  --weight_decay WEIGHT_DECAY\n",
        "                        Weight decay if we apply some.\n",
        "  --adam_epsilon ADAM_EPSILON\n",
        "                        Epsilon for Adam optimizer.\n",
        "  --warmup_steps WARMUP_STEPS\n",
        "                        Linear warmup over warmup_steps.\n",
        "  --num_workers NUM_WORKERS\n",
        "                        kwarg passed to DataLoader\n",
        "  --num_train_epochs MAX_EPOCHS\n",
        "  --train_batch_size TRAIN_BATCH_SIZE\n",
        "  --eval_batch_size EVAL_BATCH_SIZE\n",
        "  --adafactor\n",
        "  --output_dir OUTPUT_DIR\n",
        "                        The output directory where the model predictions and\n",
        "                        checkpoints will be written.\n",
        "  --fp16                Whether to use 16-bit (mixed) precision (through\n",
        "                        NVIDIA apex) instead of 32-bit\n",
        "  --fp16_opt_level FP16_OPT_LEVEL\n",
        "                        For fp16: Apex AMP optimization level selected in\n",
        "                        ['O0', 'O1', 'O2', and 'O3'].See details at\n",
        "                        https://nvidia.github.io/apex/amp.html\n",
        "  --n_tpu_cores TPU_CORES\n",
        "  --max_grad_norm GRADIENT_CLIP_VAL\n",
        "                        Max gradient norm\n",
        "  --do_train            Whether to run training.\n",
        "  --do_predict          Whether to run predictions on the test set.\n",
        "  --gradient_accumulation_steps ACCUMULATE_GRAD_BATCHES\n",
        "                        Number of updates steps to accumulate before\n",
        "                        performing a backward/update pass.\n",
        "  --seed SEED           random seed for initialization\n",
        "  --data_dir DATA_DIR   The input data dir. Should contain the training files\n",
        "                        for the CoNLL-2003 NER task.\n",
        "  --max_source_length MAX_SOURCE_LENGTH\n",
        "                        The maximum total input sequence length after\n",
        "                        tokenization. Sequences longer than this will be\n",
        "                        truncated, sequences shorter will be padded.\n",
        "  --max_target_length MAX_TARGET_LENGTH\n",
        "                        The maximum total input sequence length after\n",
        "                        tokenization. Sequences longer than this will be\n",
        "                        truncated, sequences shorter will be padded.\n",
        "  --val_max_target_length VAL_MAX_TARGET_LENGTH\n",
        "                        The maximum total input sequence length after\n",
        "                        tokenization. Sequences longer than this will be\n",
        "                        truncated, sequences shorter will be padded.\n",
        "  --test_max_target_length TEST_MAX_TARGET_LENGTH\n",
        "                        The maximum total input sequence length after\n",
        "                        tokenization. Sequences longer than this will be\n",
        "                        truncated, sequences shorter will be padded.\n",
        "  --logger_name {default,wandb,wandb_shared}\n",
        "  --n_train N_TRAIN     # examples. -1 means use all.\n",
        "  --n_val N_VAL         # examples. -1 means use all.\n",
        "  --n_test N_TEST       # examples. -1 means use all.\n",
        "  --label_smoothing LABEL_SMOOTHING\n",
        "  --prefix PREFIX       Prefix added at the beginning of each text, typically\n",
        "                        used with T5-based models.\n",
        "  --early_stopping_patience EARLY_STOPPING_PATIENCE\n",
        "                        -1 means never early stop. early_stopping_patience is\n",
        "                        measured in validation checks, not epochs. So\n",
        "                        val_check_interval will effect it.\n",
        "  --distributed-port DISTRIBUTED_PORT\n",
        "                        Port number for distributed training.\n",
        "  --model_type {rag_sequence,rag_token,bart,t5}\n",
        "                        RAG model type: sequence or token, if none specified,\n",
        "                        the type is inferred from the model_name_or_path\n",
        "  --index_name INDEX_NAME\n",
        "                        Name of the index to use: 'hf' for a canonical dataset\n",
        "                        from the datasets library (default), 'custom' for a\n",
        "                        local index, or 'legacy' for the orignal one)\n",
        "  --passages_path PASSAGES_PATH\n",
        "                        Path to the dataset of passages for custom index. More\n",
        "                        info about custom indexes in the RagRetriever\n",
        "                        documentation as well as in\n",
        "                        `examples/rag/use_own_knowledge_dataset.py`\n",
        "  --index_path INDEX_PATH\n",
        "                        Path to the faiss index for custom index. More info\n",
        "                        about custom indexes in the RagRetriever documentation\n",
        "                        as well as in\n",
        "                        `examples/rag/use_own_knowledge_dataset.py`\n",
        "  --distributed_retriever {ray,pytorch}\n",
        "                        What implementation to use for distributed retriever?\n",
        "                        If pytorch is selected, the index is loaded on\n",
        "                        training worker 0, and torch.distributed is used to\n",
        "                        handle communication between training worker 0, and\n",
        "                        the other training workers. If ray is selected, the\n",
        "                        Ray library is used to create load the index on\n",
        "                        separate processes, and Ray handles the communication\n",
        "                        between the training workers and the retrieval actors.\n",
        "  --use_dummy_dataset USE_DUMMY_DATASET\n",
        "                        Whether to use the dummy version of the dataset index.\n",
        "                        More info about custom indexes in the RagRetriever\n",
        "                        documentation as well as in\n",
        "                        `examples/rag/use_own_knowledge_dataset.py`\n",
        "  --ray-address RAY_ADDRESS\n",
        "                        The address of the Ray cluster to connect to. If not\n",
        "                        specified, Ray will attempt to automatically detect\n",
        "                        the cluster. Has no effect if pytorch is used as the\n",
        "                        distributed retriever.\n",
        "  --num_retrieval_workers NUM_RETRIEVAL_WORKERS\n",
        "                        The number of retrieval actors to use when Ray is\n",
        "                        selectedfor the distributed retriever. Has no effect\n",
        "                        when distributed_retriever is set to pytorch.\n",
        "  --profile             If True, use\n",
        "                        pytorch_lightning.profiler.AdvancedProfiler to profile\n",
        "                        the Trainer.\n",
        "\n",
        "pl.Trainer:\n",
        "  --logger [LOGGER]     Logger (or iterable collection of loggers) for\n",
        "                        experiment tracking. A ``True`` value uses the default\n",
        "                        ``TensorBoardLogger``. ``False`` will disable logging.\n",
        "                        If multiple loggers are provided and the `save_dir`\n",
        "                        property of that logger is not set, local files\n",
        "                        (checkpoints, profiler traces, etc.) are saved in\n",
        "                        ``default_root_dir`` rather than in the ``log_dir`` of\n",
        "                        any of the individual loggers. Default: ``True``.\n",
        "  --checkpoint_callback [CHECKPOINT_CALLBACK]\n",
        "                        If ``True``, enable checkpointing. Default: ``None``.\n",
        "                        .. deprecated:: v1.5 ``checkpoint_callback`` has been\n",
        "                        deprecated in v1.5 and will be removed in v1.7. Please\n",
        "                        consider using ``enable_checkpointing`` instead.\n",
        "  --enable_checkpointing [ENABLE_CHECKPOINTING]\n",
        "                        If ``True``, enable checkpointing. It will configure a\n",
        "                        default ModelCheckpoint callback if there is no user-\n",
        "                        defined ModelCheckpoint in :paramref:`~pytorch_lightni\n",
        "                        ng.trainer.trainer.Trainer.callbacks`. Default:\n",
        "                        ``True``.\n",
        "  --default_root_dir DEFAULT_ROOT_DIR\n",
        "                        Default path for logs and weights when no\n",
        "                        logger/ckpt_callback passed. Default: ``os.getcwd()``.\n",
        "                        Can be remote file paths such as `s3://mybucket/path`\n",
        "                        or 'hdfs://path/'\n",
        "  --gradient_clip_val GRADIENT_CLIP_VAL\n",
        "                        The value at which to clip gradients. Passing\n",
        "                        ``gradient_clip_val=None`` disables gradient clipping.\n",
        "                        If using Automatic Mixed Precision (AMP), the\n",
        "                        gradients will be unscaled before. Default: ``None``.\n",
        "  --gradient_clip_algorithm GRADIENT_CLIP_ALGORITHM\n",
        "                        The gradient clipping algorithm to use. Pass\n",
        "                        ``gradient_clip_algorithm=\"value\"`` to clip by value,\n",
        "                        and ``gradient_clip_algorithm=\"norm\"`` to clip by\n",
        "                        norm. By default it will be set to ``\"norm\"``.\n",
        "  --process_position PROCESS_POSITION\n",
        "                        Orders the progress bar when running multiple models\n",
        "                        on same machine. .. deprecated:: v1.5\n",
        "                        ``process_position`` has been deprecated in v1.5 and\n",
        "                        will be removed in v1.7. Please pass :class:`~pytorch_\n",
        "                        lightning.callbacks.progress.TQDMProgressBar` with\n",
        "                        ``process_position`` directly to the Trainer's\n",
        "                        ``callbacks`` argument instead.\n",
        "  --num_nodes NUM_NODES\n",
        "                        Number of GPU nodes for distributed training. Default:\n",
        "                        ``1``.\n",
        "  --num_processes NUM_PROCESSES\n",
        "                        Number of processes for distributed training with\n",
        "                        ``accelerator=\"cpu\"``. Default: ``1``.\n",
        "  --devices DEVICES     Will be mapped to either `gpus`, `tpu_cores`,\n",
        "                        `num_processes` or `ipus`, based on the accelerator\n",
        "                        type.\n",
        "  --gpus GPUS           Number of GPUs to train on (int) or which GPUs to\n",
        "                        train on (list or str) applied per node Default:\n",
        "                        ``None``.\n",
        "  --auto_select_gpus [AUTO_SELECT_GPUS]\n",
        "                        If enabled and ``gpus`` is an integer, pick available\n",
        "                        gpus automatically. This is especially useful when\n",
        "                        GPUs are configured to be in \"exclusive mode\", such\n",
        "                        that only one process at a time can access them.\n",
        "                        Default: ``False``.\n",
        "  --tpu_cores TPU_CORES\n",
        "                        How many TPU cores to train on (1 or 8) / Single TPU\n",
        "                        to train on (1) Default: ``None``.\n",
        "  --ipus IPUS           How many IPUs to train on. Default: ``None``.\n",
        "  --log_gpu_memory LOG_GPU_MEMORY\n",
        "                        None, 'min_max', 'all'. Might slow performance. ..\n",
        "                        deprecated:: v1.5 Deprecated in v1.5.0 and will be\n",
        "                        removed in v1.7.0 Please use the\n",
        "                        ``DeviceStatsMonitor`` callback directly instead.\n",
        "  --progress_bar_refresh_rate PROGRESS_BAR_REFRESH_RATE\n",
        "                        How often to refresh progress bar (in steps). Value\n",
        "                        ``0`` disables progress bar. Ignored when a custom\n",
        "                        progress bar is passed to\n",
        "                        :paramref:`~Trainer.callbacks`. Default: None, means a\n",
        "                        suitable value will be chosen based on the environment\n",
        "                        (terminal, Google COLAB, etc.). .. deprecated:: v1.5\n",
        "                        ``progress_bar_refresh_rate`` has been deprecated in\n",
        "                        v1.5 and will be removed in v1.7. Please pass :class:`\n",
        "                        ~pytorch_lightning.callbacks.progress.TQDMProgressBar`\n",
        "                        with ``refresh_rate`` directly to the Trainer's\n",
        "                        ``callbacks`` argument instead. To disable the\n",
        "                        progress bar, pass ``enable_progress_bar = False`` to\n",
        "                        the Trainer.\n",
        "  --enable_progress_bar [ENABLE_PROGRESS_BAR]\n",
        "                        Whether to enable to progress bar by default. Default:\n",
        "                        ``False``.\n",
        "  --overfit_batches OVERFIT_BATCHES\n",
        "                        Overfit a fraction of training data (float) or a set\n",
        "                        number of batches (int). Default: ``0.0``.\n",
        "  --track_grad_norm TRACK_GRAD_NORM\n",
        "                        -1 no tracking. Otherwise tracks that p-norm. May be\n",
        "                        set to 'inf' infinity-norm. If using Automatic Mixed\n",
        "                        Precision (AMP), the gradients will be unscaled before\n",
        "                        logging them. Default: ``-1``.\n",
        "  --check_val_every_n_epoch CHECK_VAL_EVERY_N_EPOCH\n",
        "                        Check val every n train epochs. Default: ``1``.\n",
        "  --fast_dev_run [FAST_DEV_RUN]\n",
        "                        Runs n if set to ``n`` (int) else 1 if set to ``True``\n",
        "                        batch(es) of train, val and test to find any bugs (ie:\n",
        "                        a sort of unit test). Default: ``False``.\n",
        "  --accumulate_grad_batches ACCUMULATE_GRAD_BATCHES\n",
        "                        Accumulates grads every k batches or as set up in the\n",
        "                        dict. Default: ``None``.\n",
        "  --max_epochs MAX_EPOCHS\n",
        "                        Stop training once this number of epochs is reached.\n",
        "                        Disabled by default (None). If both max_epochs and\n",
        "                        max_steps are not specified, defaults to ``max_epochs\n",
        "                        = 1000``. To enable infinite training, set\n",
        "                        ``max_epochs = -1``.\n",
        "  --min_epochs MIN_EPOCHS\n",
        "                        Force training for at least these many epochs.\n",
        "                        Disabled by default (None).\n",
        "  --max_steps MAX_STEPS\n",
        "                        Stop training after this number of steps. Disabled by\n",
        "                        default (-1). If ``max_steps = -1`` and ``max_epochs =\n",
        "                        None``, will default to ``max_epochs = 1000``. To\n",
        "                        enable infinite training, set ``max_epochs`` to\n",
        "                        ``-1``.\n",
        "  --min_steps MIN_STEPS\n",
        "                        Force training for at least these number of steps.\n",
        "                        Disabled by default (``None``).\n",
        "  --max_time MAX_TIME   Stop training after this amount of time has passed.\n",
        "                        Disabled by default (``None``). The time duration can\n",
        "                        be specified in the format DD:HH:MM:SS (days, hours,\n",
        "                        minutes seconds), as a :class:`datetime.timedelta`, or\n",
        "                        a dictionary with keys that will be passed to\n",
        "                        :class:`datetime.timedelta`.\n",
        "  --limit_train_batches LIMIT_TRAIN_BATCHES\n",
        "                        How much of training dataset to check (float =\n",
        "                        fraction, int = num_batches). Default: ``1.0``.\n",
        "  --limit_val_batches LIMIT_VAL_BATCHES\n",
        "                        How much of validation dataset to check (float =\n",
        "                        fraction, int = num_batches). Default: ``1.0``.\n",
        "  --limit_test_batches LIMIT_TEST_BATCHES\n",
        "                        How much of test dataset to check (float = fraction,\n",
        "                        int = num_batches). Default: ``1.0``.\n",
        "  --limit_predict_batches LIMIT_PREDICT_BATCHES\n",
        "                        How much of prediction dataset to check (float =\n",
        "                        fraction, int = num_batches). Default: ``1.0``.\n",
        "  --val_check_interval VAL_CHECK_INTERVAL\n",
        "                        How often to check the validation set. Pass a\n",
        "                        ``float`` in the range [0.0, 1.0] to check after a\n",
        "                        fraction of the training epoch. Pass an ``int`` to\n",
        "                        check after a fixed number of training batches.\n",
        "                        Default: ``1.0``.\n",
        "  --flush_logs_every_n_steps FLUSH_LOGS_EVERY_N_STEPS\n",
        "                        How often to flush logs to disk (defaults to every 100\n",
        "                        steps). .. deprecated:: v1.5\n",
        "                        ``flush_logs_every_n_steps`` has been deprecated in\n",
        "                        v1.5 and will be removed in v1.7. Please configure\n",
        "                        flushing directly in the logger instead.\n",
        "  --log_every_n_steps LOG_EVERY_N_STEPS\n",
        "                        How often to log within steps. Default: ``50``.\n",
        "  --accelerator ACCELERATOR\n",
        "                        Supports passing different accelerator types (\"cpu\",\n",
        "                        \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"auto\") as well as custom\n",
        "                        accelerator instances. .. deprecated:: v1.5 Passing\n",
        "                        training strategies (e.g., 'ddp') to ``accelerator``\n",
        "                        has been deprecated in v1.5.0 and will be removed in\n",
        "                        v1.7.0. Please use the ``strategy`` argument instead.\n",
        "  --strategy STRATEGY   Supports different training strategies with aliases as\n",
        "                        well custom strategies. Default: ``None``.\n",
        "  --sync_batchnorm [SYNC_BATCHNORM]\n",
        "                        Synchronize batch norm layers between process\n",
        "                        groups/whole world. Default: ``False``.\n",
        "  --precision PRECISION\n",
        "                        Double precision (64), full precision (32), half\n",
        "                        precision (16) or bfloat16 precision (bf16). Can be\n",
        "                        used on CPU, GPU, TPUs, HPUs or IPUs. Default: ``32``.\n",
        "  --enable_model_summary [ENABLE_MODEL_SUMMARY]\n",
        "                        Whether to enable model summarization by default.\n",
        "                        Default: ``True``.\n",
        "  --weights_summary WEIGHTS_SUMMARY\n",
        "                        Prints a summary of the weights when training begins.\n",
        "                        .. deprecated:: v1.5 ``weights_summary`` has been\n",
        "                        deprecated in v1.5 and will be removed in v1.7. To\n",
        "                        disable the summary, pass ``enable_model_summary =\n",
        "                        False`` to the Trainer. To customize the summary, pass\n",
        "                        :class:`~pytorch_lightning.callbacks.model_summary.Mod\n",
        "                        elSummary` directly to the Trainer's ``callbacks``\n",
        "                        argument.\n",
        "  --weights_save_path WEIGHTS_SAVE_PATH\n",
        "                        Where to save weights if specified. Will override\n",
        "                        default_root_dir for checkpoints only. Use this if for\n",
        "                        whatever reason you need the checkpoints stored in a\n",
        "                        different place than the logs written in\n",
        "                        `default_root_dir`. Can be remote file paths such as\n",
        "                        `s3://mybucket/path` or 'hdfs://path/' Defaults to\n",
        "                        `default_root_dir`. .. deprecated:: v1.6\n",
        "                        ``weights_save_path`` has been deprecated in v1.6 and\n",
        "                        will be removed in v1.8. Please pass ``dirpath``\n",
        "                        directly to the :class:`~pytorch_lightning.callbacks.m\n",
        "                        odel_checkpoint.ModelCheckpoint` callback.\n",
        "  --num_sanity_val_steps NUM_SANITY_VAL_STEPS\n",
        "                        Sanity check runs n validation batches before starting\n",
        "                        the training routine. Set it to `-1` to run all\n",
        "                        batches in all validation dataloaders. Default: ``2``.\n",
        "  --resume_from_checkpoint RESUME_FROM_CHECKPOINT\n",
        "                        Path/URL of the checkpoint from which training is\n",
        "                        resumed. If there is no checkpoint file at the path,\n",
        "                        an exception is raised. If resuming from mid-epoch\n",
        "                        checkpoint, training will start from the beginning of\n",
        "                        the next epoch. .. deprecated:: v1.5\n",
        "                        ``resume_from_checkpoint`` is deprecated in v1.5 and\n",
        "                        will be removed in v2.0. Please pass the path to\n",
        "                        ``Trainer.fit(..., ckpt_path=...)`` instead.\n",
        "  --profiler PROFILER   To profile individual steps during training and assist\n",
        "                        in identifying bottlenecks. Default: ``None``.\n",
        "  --benchmark [BENCHMARK]\n",
        "                        Sets ``torch.backends.cudnn.benchmark``. Defaults to\n",
        "                        ``True`` if :paramref:`~pytorch_lightning.trainer.trai\n",
        "                        ner.Trainer.deterministic` is ``False``. Overwrite to\n",
        "                        manually set a different value. Default: ``None``.\n",
        "  --deterministic [DETERMINISTIC]\n",
        "                        If ``True``, sets whether PyTorch operations must use\n",
        "                        deterministic algorithms. Default: ``False``.\n",
        "  --reload_dataloaders_every_n_epochs RELOAD_DATALOADERS_EVERY_N_EPOCHS\n",
        "                        Set to a non-negative integer to reload dataloaders\n",
        "                        every n epochs. Default: ``0``.\n",
        "  --auto_lr_find [AUTO_LR_FIND]\n",
        "                        If set to True, will make trainer.tune() run a\n",
        "                        learning rate finder, trying to optimize initial\n",
        "                        learning for faster convergence. trainer.tune() method\n",
        "                        will set the suggested learning rate in self.lr or\n",
        "                        self.learning_rate in the LightningModule. To use a\n",
        "                        different key set a string instead of True with the\n",
        "                        key name. Default: ``False``.\n",
        "  --replace_sampler_ddp [REPLACE_SAMPLER_DDP]\n",
        "                        Explicitly enables or disables sampler replacement. If\n",
        "                        not specified this will toggled automatically when DDP\n",
        "                        is used. By default it will add ``shuffle=True`` for\n",
        "                        train sampler and ``shuffle=False`` for val/test\n",
        "                        sampler. If you want to customize it, you can set\n",
        "                        ``replace_sampler_ddp=False`` and add your own\n",
        "                        distributed sampler.\n",
        "  --detect_anomaly [DETECT_ANOMALY]\n",
        "                        Enable anomaly detection for the autograd engine.\n",
        "                        Default: ``False``.\n",
        "  --auto_scale_batch_size [AUTO_SCALE_BATCH_SIZE]\n",
        "                        If set to True, will `initially` run a batch size\n",
        "                        finder trying to find the largest batch size that fits\n",
        "                        into memory. The result will be stored in\n",
        "                        self.batch_size in the LightningModule. Additionally,\n",
        "                        can be set to either `power` that estimates the batch\n",
        "                        size through a power search or `binsearch` that\n",
        "                        estimates the batch size through a binary search.\n",
        "                        Default: ``False``.\n",
        "  --prepare_data_per_node [PREPARE_DATA_PER_NODE]\n",
        "                        If True, each LOCAL_RANK=0 will call prepare data.\n",
        "                        Otherwise only NODE_RANK=0, LOCAL_RANK=0 will prepare\n",
        "                        data .. deprecated:: v1.5 Deprecated in v1.5.0 and\n",
        "                        will be removed in v1.7.0 Please set\n",
        "                        ``prepare_data_per_node`` in ``LightningDataModule``\n",
        "                        and/or ``LightningModule`` directly instead.\n",
        "  --plugins PLUGINS     Plugins allow modification of core behavior like ddp\n",
        "                        and amp, and enable custom lightning plugins. Default:\n",
        "                        ``None``.\n",
        "  --amp_backend AMP_BACKEND\n",
        "                        The mixed precision backend to use (\"native\" or\n",
        "                        \"apex\"). Default: ``'native''``.\n",
        "  --amp_level AMP_LEVEL\n",
        "                        The optimization level to use (O1, O2, etc...). By\n",
        "                        default it will be set to \"O2\" if ``amp_backend`` is\n",
        "                        set to \"apex\".\n",
        "  --move_metrics_to_cpu [MOVE_METRICS_TO_CPU]\n",
        "                        Whether to force internal logged metrics to be moved\n",
        "                        to cpu. This can save some gpu memory, but can make\n",
        "                        training slower. Use with attention. Default:\n",
        "                        ``False``.\n",
        "  --multiple_trainloader_mode MULTIPLE_TRAINLOADER_MODE\n",
        "                        How to loop over the datasets when there are multiple\n",
        "                        train loaders. In 'max_size_cycle' mode, the trainer\n",
        "                        ends one epoch when the largest dataset is traversed,\n",
        "                        and smaller datasets reload when running out of their\n",
        "                        data. In 'min_size' mode, all the datasets reload when\n",
        "                        reaching the minimum length of datasets. Default:\n",
        "                        ``\"max_size_cycle\"``.\n",
        "  --stochastic_weight_avg [STOCHASTIC_WEIGHT_AVG]\n",
        "                        Whether to use `Stochastic Weight Averaging (SWA)\n",
        "                        <https://pytorch.org/blog/pytorch-1.6-now-includes-\n",
        "                        stochastic-weight-averaging/>`_. Default: ``False``.\n",
        "                        .. deprecated:: v1.5 ``stochastic_weight_avg`` has\n",
        "                        been deprecated in v1.5 and will be removed in v1.7.\n",
        "                        Please pass :class:`~pytorch_lightning.callbacks.stoch\n",
        "                        astic_weight_avg.StochasticWeightAveraging` directly\n",
        "                        to the Trainer's ``callbacks`` argument instead.\n",
        "  --terminate_on_nan [TERMINATE_ON_NAN]\n",
        "                        If set to True, will terminate training (by raising a\n",
        "                        `ValueError`) at the end of each training batch, if\n",
        "                        any of the parameters or the loss are NaN or +/-inf.\n",
        "                        .. deprecated:: v1.5 Trainer argument\n",
        "                        ``terminate_on_nan`` was deprecated in v1.5 and will\n",
        "                        be removed in 1.7. Please use ``detect_anomaly``\n",
        "                        instead.\n",
        "```                        "
      ],
      "metadata": {
        "id": "z7oO_W9FV5gO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A3. Pinned Revisions"
      ],
      "metadata": {
        "id": "ZdcUMIM8y8Uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4/1/22 - Working, Pre-Rip**\n",
        "\n",
        "* This version of the Notebook runs successfully using wikipedia. Test and validation scores are 0, though, on GoT questions."
      ],
      "metadata": {
        "id": "-XVSkuXyy-7D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaNqt9Ez3_SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A4. Retrieve Script Files"
      ],
      "metadata": {
        "id": "loz1DF2KSeDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code for this example is spread across 5 different scripts."
      ],
      "metadata": {
        "id": "j9SsbQzpStq-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayuM6jICSeDO"
      },
      "source": [
        "import wget \n",
        "\n",
        "#wget.download('https://raw.githubusercontent.com/huggingface/transformers/main/examples/research_projects/rag/finetune_rag.py')\n",
        "#wget.download('https://raw.githubusercontent.com/huggingface/transformers/main/examples/research_projects/rag/callbacks_rag.py')\n",
        "#wget.download('https://raw.githubusercontent.com/huggingface/transformers/main/examples/research_projects/rag/utils_rag.py')\n",
        "#wget.download('https://raw.githubusercontent.com/huggingface/transformers/main/examples/research_projects/rag/distributed_pytorch_retriever.py')\n",
        "#wget.download('https://raw.githubusercontent.com/huggingface/transformers/main/examples/research_projects/rag/lightning_base.py')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}